{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "from collections import defaultdict, Counter, namedtuple\n",
    "from itertools import combinations\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import editdistance\n",
    "\n",
    "PROJECT_PATH = '/Users/guydavidson/projects/game-generation-modeling'\n",
    "sys.path.append(PROJECT_PATH)\n",
    "\n",
    "from src.room_and_object_types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {x: mpl.rcParams[x] for x in mpl.rcParams.keys() if x.startswith('text')}\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and munge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema.validate_schema import load_and_validate_game_schema\n",
    "SCHEMA_FILE = '../schema/game_schema_with_refs.json'\n",
    "GAME_SCHEMAS_FILE = '../schema/interactive_beta.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_to_df_row(game_schema):\n",
    "    row = defaultdict(list)\n",
    "    row.update(game_schema['metadata'])\n",
    "\n",
    "    row['game_name'] = row['prolific_id']\n",
    "    row['is_throwing'] = 0\n",
    "    row['is_building'] = 0\n",
    "    row['is_organizing'] = 0\n",
    "    objects_with_predicates = []\n",
    "\n",
    "    if 'throwing' in game_schema:\n",
    "        throwing_game = game_schema['throwing']\n",
    "        row['is_throwing'] = 1\n",
    "        row['throwing_objects'] = throwing_game['what']\n",
    "        row['throwing_goal'] = throwing_game['goal']\n",
    "        \n",
    "        for key in ('to', 'from', 'on'):\n",
    "            if key in throwing_game:\n",
    "                value = throwing_game[key]\n",
    "                row[f'throwing_{key}'] = value\n",
    "                objects_with_predicates.extend(value)\n",
    "\n",
    "    if 'building' in game_schema:\n",
    "        building_game = game_schema['building']\n",
    "        row['is_building'] = 1\n",
    "        row['building_objects'] = building_game['objects']\n",
    "        row['building_goal'] = building_game['goal']\n",
    "        row['building_structure'] = building_game['structure'] if 'structure' in building_game else None\n",
    "        row['building_order'] = building_game['order'] if 'order' in building_game else None\n",
    "\n",
    "        if 'on' in building_game:\n",
    "            objects_with_predicates.append(building_game['on'])\n",
    "\n",
    "    if 'organizing' in game_schema:\n",
    "        row['is_organizing'] = 1\n",
    "        row['organizing'] = game_schema['organizing']\n",
    "        for org_game in game_schema['organizing']:\n",
    "            row['organizing_objects'].extend(org_game['what'])\n",
    "            if 'from' in org_game:\n",
    "                objects_with_predicates.append(org_game['from'])\n",
    "            objects_with_predicates.extend(org_game['to'])\n",
    "\n",
    "    row['objects_with_predicates'] = objects_with_predicates\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stats_df = pd.read_csv('../data/dsl_statistics_interactive.csv', index_col='Index')\n",
    "raw_stats_df.game_name = raw_stats_df.game_name.astype(str)\n",
    "raw_stats_df = raw_stats_df.assign(old_game_name=raw_stats_df.game_name.apply(lambda x: x.split('-')[0]))\n",
    "print(raw_stats_df.game_name.size - raw_stats_df.game_name.nunique())\n",
    "print(raw_stats_df.shape)\n",
    "\n",
    "game_schemas = load_and_validate_game_schema(GAME_SCHEMAS_FILE, SCHEMA_FILE)\n",
    "game_schema_rows = [schema_to_df_row(game_schema) for game_schema in game_schemas]\n",
    "\n",
    "schema_df = pd.DataFrame(game_schema_rows)\n",
    "print(schema_df.prolific_id.size - schema_df.prolific_id.nunique())\n",
    "print(schema_df.shape)\n",
    "# manual_df = pd.read_csv('../data/manual_dsl_statistics.csv')\n",
    "stats_df = raw_stats_df.merge(schema_df, left_on='old_game_name', right_on='game_name', suffixes=['', '_schema'], copy=True)\n",
    "print(stats_df.shape)\n",
    "\n",
    "firestore_stats_df = pd.read_csv('../data/interactive_beta_firestore_statistics.csv')\n",
    "firestore_stats_df = firestore_stats_df.rename(columns={key: key.replace('game_', 'raw_game_') for key in firestore_stats_df.columns if key.startswith('game_')})\n",
    "firestore_stats_df = firestore_stats_df.rename(columns={key: key.replace('gameScore_', 'raw_game_') for key in firestore_stats_df.columns if key.startswith('gameScore_')})\n",
    "print(firestore_stats_df.prolific_id.size - firestore_stats_df.prolific_id.nunique())\n",
    "print(firestore_stats_df.shape)\n",
    "\n",
    "stats_df = stats_df.merge(firestore_stats_df, on='prolific_id', copy=True)\n",
    "\n",
    "stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df = pd.read_csv('../data/dsl_repeated_structures_temporal_operator.csv')\n",
    "print(repeated_structures_df.shape)\n",
    "\n",
    "print(repeated_structures_df.loc[87].structure, repeated_structures_df.loc[87, 'count'])\n",
    "print(repeated_structures_df.loc[93].structure, repeated_structures_df.loc[93, 'count'])\n",
    "\n",
    "repeated_structures_df.loc[87, 'count'] += repeated_structures_df.loc[93, 'count']\n",
    "print(repeated_structures_df.loc[87].structure, repeated_structures_df.loc[87, 'count'])\n",
    "\n",
    "\n",
    "repeated_structures_df = repeated_structures_df.drop(93, axis=0)\n",
    "repeated_structures_df = repeated_structures_df.reindex()\n",
    "print(repeated_structures_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.loc[stats_df.terminal_exists.isna(), 'terminal_exists'] = False\n",
    "\n",
    "room = np.zeros((len(stats_df),), dtype=np.int32)\n",
    "room[['medium' in d for d in stats_df.domain_name]] = 1\n",
    "room[['many' in d for d in stats_df.domain_name]] = 2\n",
    "\n",
    "room_name = ['Few'] * len(stats_df)\n",
    "stats_df = stats_df.assign(room=room, room_name=room_name)\n",
    "\n",
    "stats_df.loc[['medium' in d for d in stats_df.domain_name], 'room_name'] = 'Medium'\n",
    "stats_df.loc[['many' in d for d in stats_df.domain_name], 'room_name'] = 'Many'\n",
    "\n",
    "DIFFICULTIES = ('Very Easy', 'Easy', 'Medium', 'Hard', 'Very Hard')\n",
    "stats_df = stats_df.assign(difficulty=[DIFFICULTIES[i] for i in stats_df.raw_game_difficulty])\n",
    "\n",
    "\n",
    "stats_df.src_file = stats_df.src_file.apply(lambda s: s.replace('problems-', '').replace('.pddl', ''))\n",
    "room[['interactive' in s for s in stats_df.src_file]] = 3\n",
    "stats_df = stats_df.assign(src=room)\n",
    "\n",
    "def list_from_text(list_text):\n",
    "    if isinstance(list_text, str):\n",
    "        return np.fromstring(list_text[1:-1], sep=',', dtype=np.int32)\n",
    "    \n",
    "    return []\n",
    "\n",
    "stats_df = stats_df.assign(length_of_then=stats_df.length_of_then.apply(list_from_text))\n",
    "stats_df = stats_df.assign(setup_objects_quantified=stats_df.setup_objects_quantified.apply(list_from_text))\n",
    "stats_df = stats_df.assign(preference_objects_quantified=stats_df.preference_objects_quantified.apply(list_from_text))\n",
    "\n",
    "def average_list_series(df, name):\n",
    "    avg = np.empty_like(df[name])\n",
    "    avg[:] = np.NaN\n",
    "    for i, entry in df[name].items():\n",
    "        if len(entry) > 0:\n",
    "            avg[i] = np.mean(entry)\n",
    "\n",
    "    return df.assign(**{f'average_{name}': avg})\n",
    "\n",
    "stats_df = average_list_series(stats_df, 'length_of_then')\n",
    "stats_df = average_list_series(stats_df, 'setup_objects_quantified')\n",
    "stats_df = average_list_series(stats_df, 'preference_objects_quantified')\n",
    "\n",
    "GAME_TYPES = ('throwing', 'building', 'organizing')\n",
    "game_type_data = [[type_name for type_name in GAME_TYPES if row[f'is_{type_name}']]\n",
    "    for i, row in stats_df.iterrows()]\n",
    "\n",
    "\n",
    "for col in stats_df.columns:\n",
    "    if col.startswith('is_'):\n",
    "        stats_df[col] = stats_df[col].astype('bool')\n",
    "\n",
    "\n",
    "stats_df = stats_df.assign(game_type=game_type_data)\n",
    "stats_df = stats_df.assign(game_type_str=['_'.join(sorted(types)) for types in stats_df.game_type])\n",
    "\n",
    "def dict_from_str_with_key_filters(keys_to_filter):\n",
    "    def inner(dict_str):\n",
    "        d = json.loads(dict_str.replace(\"'\",'\"'))\n",
    "        for key in keys_to_filter:\n",
    "            if key in d:\n",
    "                del d[key]\n",
    "\n",
    "        return d\n",
    "\n",
    "    return inner\n",
    "\n",
    "OBJECT_TYPES_REFERENCED_KEYS_TO_FILTER = ('back', 'front', 'left', 'right', 'front_left_corner', 'upright', 'upside_down', 'sideways')\n",
    "\n",
    "stats_df = stats_df.assign(object_types_referenced=stats_df.object_types_referenced.apply(dict_from_str_with_key_filters(OBJECT_TYPES_REFERENCED_KEYS_TO_FILTER)))\n",
    "stats_df = stats_df.assign(predicates_referenced=stats_df.predicates_referenced.apply(dict_from_str_with_key_filters([])))\n",
    "stats_df = stats_df.assign(type_to_pred_counts=stats_df.type_to_pred_counts.apply(dict_from_str_with_key_filters(OBJECT_TYPES_REFERENCED_KEYS_TO_FILTER)))\n",
    "\n",
    "stats_df.loc[stats_df.edited_game_fields.isna(), 'edited_game_fields'] = ''\n",
    "stats_df = stats_df.assign(edited_game_fields=[fields.split(',') if fields else '' for fields in stats_df.edited_game_fields])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = set()\n",
    "for type_dict in stats_df.object_types_referenced:\n",
    "    all_types.update(type_dict.keys())\n",
    "\n",
    "\n",
    "for category_objects in CATEGORIES_TO_TYPES.values():\n",
    "    for obj in category_objects:\n",
    "        if obj not in all_types:\n",
    "            print(f'Found unused type: \"{obj}\"')\n",
    "        else:\n",
    "            all_types.remove(obj)\n",
    "\n",
    "if len(all_types) > 0:\n",
    "    print(f'Found unaccounted types: {all_types}')\n",
    "\n",
    "\n",
    "object_categories_referenced = []\n",
    "object_categories_referenced_total = []\n",
    "\n",
    "for object_to_count_dict in stats_df.object_types_referenced:\n",
    "    refs = defaultdict(lambda: 0)\n",
    "    total_refs = defaultdict(lambda: 0)\n",
    "\n",
    "    for obj, count in object_to_count_dict.items():\n",
    "        obj_type = TYPES_TO_CATEGORIES[obj]\n",
    "        refs[obj_type] += 1\n",
    "        total_refs[obj_type] += count\n",
    "\n",
    "    object_categories_referenced.append(dict(refs))\n",
    "    object_categories_referenced_total.append(dict(total_refs))\n",
    "\n",
    "stats_df = stats_df.assign(object_categories_referenced=object_categories_referenced, object_categories_referenced_total=object_categories_referenced_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_valid_rooms = []\n",
    "for idx, obj_types in enumerate(stats_df.object_types_referenced):\n",
    "    g = [room_name for room_name, room_objects in ROOMS_TO_AVAILABLE_OBJECTS.items() \n",
    "        if set(obj_types.keys()) <= room_objects]\n",
    "\n",
    "    if stats_df.room_name[idx] not in g:\n",
    "        room_objects = ROOMS_TO_AVAILABLE_OBJECTS[stats_df.room_name[idx]]\n",
    "        print(idx, stats_df.game_name[idx], stats_df.room_name[idx], g, set(obj_types.keys()) - room_objects)\n",
    "    \n",
    "    game_valid_rooms.append(g)\n",
    "\n",
    "# print(game_valid_rooms)\n",
    "\n",
    "\n",
    "stats_df = stats_df.assign(game_valid_rooms=game_valid_rooms, num_game_valid_rooms=[len(g) for g in game_valid_rooms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_pred_counts = []\n",
    "pred_to_type_counts = []\n",
    "pred_to_category_counts = []\n",
    "\n",
    "for type_to_pred in stats_df.type_to_pred_counts:\n",
    "    cat_to_pred = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    pred_to_type = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    pred_to_cat = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for type_name, pred_counts in type_to_pred.items():\n",
    "        cat_name = TYPES_TO_CATEGORIES[type_name]\n",
    "        for pred, count in pred_counts.items():\n",
    "            cat_to_pred[cat_name][pred] += count\n",
    "            pred_to_type[pred][type_name] += count\n",
    "            pred_to_cat[pred][cat_name] += count\n",
    "\n",
    "    category_to_pred_counts.append({outer_key: dict(inner_dict) for outer_key, inner_dict in cat_to_pred.items()})\n",
    "    pred_to_type_counts.append({outer_key: dict(inner_dict) for outer_key, inner_dict in pred_to_type.items()})\n",
    "    pred_to_category_counts.append({outer_key: dict(inner_dict) for outer_key, inner_dict in pred_to_cat.items()})\n",
    "    \n",
    "stats_df = stats_df.assign(category_to_pred_counts=category_to_pred_counts, pred_to_type_counts=pred_to_type_counts, pred_to_category_counts=pred_to_category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFICULTIES = ('Very Easy', 'Easy', 'Medium', 'Hard', 'Very Hard')\n",
    "\n",
    "REORDERED_COLUMNS = ['src', 'src_file', 'game_name', 'domain_name', 'room', 'room_name',\n",
    "    'num_preferences', 'length_of_then', 'average_length_of_then',\n",
    "    'setup_objects_quantified', 'average_setup_objects_quantified',\n",
    "    'preference_objects_quantified', 'average_preference_objects_quantified',\n",
    "    'terminal_exists', 'object_types_referenced', 'predicates_referenced', \n",
    "    'type_to_pred_counts', 'category_to_pred_counts', 'pred_to_type_counts', 'pred_to_category_counts',\n",
    "    'object_categories_referenced', 'object_categories_referenced_total',\n",
    "    'game_valid_rooms', 'num_game_valid_rooms',\n",
    "    'max_depth', 'ast_nodes', 'setup_nodes',\n",
    "    'game_type', 'game_type_str', 'is_throwing', 'is_building', 'is_organizing', \n",
    "    'objects_with_predicates',\n",
    "    'throwing_objects', 'throwing_goal', 'throwing_to', 'throwing_from', 'throwing_on',\n",
    "    'building_objects', 'building_goal', 'building_structure', 'building_order', \n",
    "    'organizing', 'organizing_objects',\n",
    "    'raw_game_setup', 'raw_game_gameplay', 'raw_game_scoring',\n",
    "    'raw_game_difficulty', 'raw_game_firstTimeScore', 'raw_game_score',\n",
    "    'raw_game_thoughts', 'raw_game_edited', 'edited_game_fields', 'difficulty',\n",
    "]\n",
    "stats_df = stats_df.reindex(columns=REORDERED_COLUMNS)\n",
    "stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(int)\n",
    "for i, game_dict in enumerate(category_to_pred_counts):\n",
    "    if 'building' in game_dict:\n",
    "        for key, count in game_dict['building'].items():\n",
    "            if key == 'touch':\n",
    "                print(i)\n",
    "            d[key] += count\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe columns readme:\n",
    "* `src/src_file`: which file the data came from (survey by specific room or interactive beta)\n",
    "* `game_name`: room-\\[row number in my spreadsheet\\].\n",
    "* `domain_name`: the room identifier as it's iun the games (domain is a PDDL thing)\n",
    "* `room/room_name`: simplifications of the room designation from the game/domain names to ease working with the data.\n",
    "* `num_preferences`: how many preferences I used to represent the game.\n",
    "* `length_of_then`: length of all `then` operators in this game.\n",
    "* `setup/preference_objects_quantified`: average number of objects quantified over in quantifiers (`exists`/`forall`) in the game representation, split by which section of the game it's in.\n",
    "* `terminal_exists`: whether the game uses a `terminal` clause.\n",
    "* `object_types_referenced`: how many times each object type was quantified in each game, combined between the setup and preferences. \n",
    "* `object_categories_referenced`: how many times each game refers to object types from each category (as coded above)\n",
    "* `predicates_referenced`: how many times each predicate was referenced in each game (as above, combined between setup and preferences). \n",
    "* `type_to_pred_counts`: a mapping, for each game, from object type, to how many times it's used with each predicate\n",
    "* `category_to_pred_counts`: same as above, but for object categories -- for each, game, from each object category, to how many times it's used with each predicate\n",
    "* `pred_to_type_counts`: same two above, but inverted -- for each game, for each predicate, how often it's used with each object type\n",
    "* `pred_to_category_counts`: same as above, but for object categories, rather than individual types -- for each game, for each predicate, how often it's used with objects from each type\n",
    "* `game_valid_rooms`: in which rooms is this game valid, by the types of objects it appears in\n",
    "* `num_game_valid_rooms`: same as above, but as a number, rather than a list of room names\n",
    "* `max_depth`: what's the deepest the game's AST goes\n",
    "* `ast_nodes`: how many total nodes of type AST (so not strings, lists, etc.) exist in the AST.\n",
    "* `is_throwing/building/organizing`: does the schema representaiton of this game utilize this sort of block?\n",
    "* `game_type`: a combination of the above into a single list\n",
    "* `game_type_str`: a combination of the above into a sorted and joined string\n",
    "* `objects_with_predicates`: a list of all of the `objectWithPredicate` types used in the schema representation of this game\n",
    "* `throwing_*/building_*/organizing_*`: individual fields from the schema representation for each type.\n",
    "* `raw_game_*`: raw data from the participants, as loaded from our firestore DB\n",
    "* `raw_game_edited`: did participants opt to edit their games after playing them?\n",
    "* `edited_game_fields`: for participants who edited their games, which fields did they edit?\n",
    "* `difficulty`: the participant-reported difficulty rating converted to a string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema-based analyses\n",
    "## How many games of each type exist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_type_counts = stats_df.groupby(['is_throwing', 'is_building', 'is_organizing']).size().reset_index().rename(columns={0: 'num'})\n",
    "print(game_type_counts)\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for index, row in game_type_counts.iterrows():\n",
    "    elements = []\n",
    "    if row.is_throwing: elements.append('throwing') \n",
    "    if row.is_building: elements.append('building') \n",
    "    if row.is_organizing: elements.append('organizing') \n",
    "    labels.append('+\\n'.join(elements))\n",
    "    values.append(row.num)\n",
    "\n",
    "x_values = np.arange(len(values))\n",
    "plt.bar(x_values, values)\n",
    "plt.xticks(x_values, labels=labels)\n",
    "plt.title('Count of games by type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_TEMPLATE = r'''\\begin{{figure}}[!htb]\n",
    "% \\vspace{{-0.225in}}\n",
    "\\centering\n",
    "\\includegraphics[width=\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "% \\vspace{{-0.2in}}\n",
    "\\end{{figure}}\n",
    "'''\n",
    "WRAPFIGURE_TEMPLATE = r'''\\begin{{wrapfigure}}{{r}}{{0.5\\linewidth}}\n",
    "\\vspace{{-.3in}}\n",
    "\\begin{{spacing}}{{1.0}}\n",
    "\\centering\n",
    "\\includegraphics[width=0.95\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "\\end{{spacing}}\n",
    "% \\vspace{{-.25in}}\n",
    "\\end{{wrapfigure}}'''\n",
    "\n",
    "SAVE_PATH_PREFIX = '../figures'\n",
    "\n",
    "\n",
    "def save_plot(save_path, bbox_inches='tight', should_print=False):\n",
    "    if save_path is not None:\n",
    "        save_path_no_ext = os.path.splitext(save_path)[0]\n",
    "        if should_print:\n",
    "            print('Figure:\\n')\n",
    "            print(FIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "            print('\\nWrapfigure:\\n')\n",
    "            print(WRAPFIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "            print('')\n",
    "        \n",
    "        if not save_path.startswith(SAVE_PATH_PREFIX):\n",
    "            save_path = os.path.join(SAVE_PATH_PREFIX, save_path)\n",
    "        \n",
    "        save_path = os.path.abspath(save_path)\n",
    "        folder, filename = os.path.split(save_path)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=bbox_inches, facecolor=plt.gcf().get_facecolor(), edgecolor='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_new_histogram_results(all_results, new_results, key):\n",
    "    if isinstance(new_results, (list, tuple)):\n",
    "        all_results[key].extend(new_results)\n",
    "    else:\n",
    "        all_results[key].append(new_results)\n",
    "\n",
    "\n",
    "def _extract_histogram_data(df, group_by_col, row_value_func, split_group_by_values):\n",
    "    results_by_key = defaultdict(list)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        group_by_key = row[group_by_col]\n",
    "        row_values = row_value_func(row)\n",
    "\n",
    "        # single key\n",
    "        if isinstance(group_by_key, (str, int)):\n",
    "            _add_new_histogram_results(results_by_key, row_values, group_by_key)\n",
    "        \n",
    "        # multiple keys\n",
    "        else:\n",
    "            if split_group_by_values:\n",
    "                for key in group_by_key:\n",
    "                    _add_new_histogram_results(results_by_key, row_values, key)\n",
    "\n",
    "            else:\n",
    "                group_by_key = '_'.join(sorted(group_by_key))\n",
    "                _add_new_histogram_results(results_by_key, row_values, group_by_key)\n",
    "\n",
    "    return results_by_key\n",
    "\n",
    "\n",
    "def _add_new_bar_chart_results(all_results, new_results, key):    \n",
    "    if isinstance(new_results, (list, tuple)):\n",
    "        for new_res in new_results:\n",
    "            _add_new_bar_chart_results(all_results, new_res, key)\n",
    "\n",
    "    elif isinstance(new_results, dict):\n",
    "        for result_key in new_results:\n",
    "            all_results[key][result_key] += new_results[result_key]\n",
    "\n",
    "    elif isinstance(new_results, (str, int)):\n",
    "        all_results[key][new_results] += 1\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'_add_new_bar_chart_results expected dict (or list/tuple of dicts), received {type(new_results)}: {new_results}')\n",
    "\n",
    "\n",
    "def _extract_bar_chart_data(df, group_by_col, row_value_func, split_group_by_values, swap_outer_inner_keys=False):\n",
    "    results_by_key = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        group_by_key = row[group_by_col]\n",
    "        row_values = row_value_func(row)\n",
    "\n",
    "        # single key\n",
    "        if isinstance(group_by_key, (str, int)):\n",
    "            _add_new_bar_chart_results(results_by_key, row_values, group_by_key)\n",
    "        \n",
    "        # multiple keys\n",
    "        else:\n",
    "            if split_group_by_values:\n",
    "                for key in group_by_key:\n",
    "                    _add_new_bar_chart_results(results_by_key, row_values, key)\n",
    "\n",
    "            else:\n",
    "                group_by_key = '_'.join(sorted(group_by_key))\n",
    "                _add_new_bar_chart_results(results_by_key, row_values, group_by_key)\n",
    "\n",
    "    if swap_outer_inner_keys:\n",
    "        swapped_results_by_key = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "        for outer_key, inner_dict in results_by_key.items():\n",
    "            for inner_key, count in inner_dict.items():\n",
    "                swapped_results_by_key[inner_key][outer_key] = count\n",
    "\n",
    "        return swapped_results_by_key\n",
    "\n",
    "    return results_by_key\n",
    "\n",
    "\n",
    "def parallel_histograms(df, group_by_col, row_value_func, split_group_by_values=False,\n",
    "    figsize=(16, 6), plot_density=True, title='',\n",
    "    super_title_fontsize=24, ax_title_fontsize=16, ax_label_fontsize=16):\n",
    "\n",
    "    results_by_key = _extract_histogram_data(df, group_by_col, row_value_func, split_group_by_values)\n",
    "\n",
    "    global_min = min([min(values) for values in results_by_key.values() if len(values) > 0])\n",
    "    global_max = max([max(values) for values in results_by_key.values() if len(values) > 0])\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(results_by_key), figsize=figsize)\n",
    "\n",
    "    for index, key in enumerate(results_by_key):\n",
    "        ax = axes[index]\n",
    "        ax.hist(results_by_key[key], range=(global_min, global_max), density=plot_density)\n",
    "        ax.set_title(key, fontsize=ax_title_fontsize)\n",
    "\n",
    "        if index == 0:\n",
    "             ax.set_ylabel('Density' if plot_density else 'Count', fontsize=ax_label_fontsize)\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=super_title_fontsize)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def single_ax_histograms(df, group_by_col, row_value_func, split_group_by_values=False,\n",
    "    figsize=(8, 6), plot_density=False, stacked=True, title='', cmap='tab10', legend_loc='best', xlabel='',\n",
    "    super_title_fontsize=24, ax_title_fontsize=16, ax_label_fontsize=16):\n",
    "\n",
    "    results_by_key = _extract_histogram_data(df, group_by_col, row_value_func, split_group_by_values)\n",
    "    keys = results_by_key.keys()\n",
    "    values = [results_by_key[key] for key in keys]\n",
    "    colormap = plt.cm.get_cmap(cmap)\n",
    "    colors = [colormap(i) for i in range(len(keys))]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.hist(values, label=list(keys), density=plot_density, stacked=stacked, color=colors)\n",
    "    plt.legend(loc=legend_loc)\n",
    "    plt.title(title, fontsize=super_title_fontsize)\n",
    "    plt.ylabel('Density' if plot_density else 'Count', fontsize=ax_label_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=ax_label_fontsize)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def single_ax_bar_chart(df, group_by_col, row_value_func, split_group_by_values=False, swap_outer_inner_keys=False, *,\n",
    "    ax=None, figsize=(8, 6), title='', cmap='tab10',\n",
    "    show_legend=True, legend_loc='best', legend_bbox_to_anchor=None, legend_from_color_dict_entries=False,\n",
    "    xlabel='', ylabel='Count',\n",
    "    super_title_fontsize=24, ax_title_fontsize=16, ax_label_fontsize=16,\n",
    "    inner_key_order=None, outer_key_order=None, normalize_columns=False, vertical_bar_labels=False, \n",
    "    label_join_str=' +\\n', color_dict=None, min_column_count_to_plot=None, min_category_count_to_plot=None,  \n",
    "    save_path=None, print_save_latex=False):\n",
    "\n",
    "    results_by_key = _extract_bar_chart_data(df, group_by_col, row_value_func, split_group_by_values, swap_outer_inner_keys)\n",
    "    single_ax_bar_chart_from_results(results_by_key, ax=ax, figsize=figsize, title=title, cmap=cmap, \n",
    "        show_legend=show_legend, legend_loc=legend_loc, \n",
    "        legend_bbox_to_anchor=legend_bbox_to_anchor, legend_from_color_dict_entries=legend_from_color_dict_entries,\n",
    "        xlabel=xlabel, ylabel=ylabel, super_title_fontsize=super_title_fontsize,\n",
    "        ax_title_fontsize=ax_title_fontsize, ax_label_fontsize=ax_label_fontsize,\n",
    "        inner_key_order=inner_key_order, outer_key_order=outer_key_order, \n",
    "        normalize_columns=normalize_columns, vertical_bar_labels=vertical_bar_labels, \n",
    "        label_join_str=label_join_str, color_dict=color_dict, \n",
    "        min_column_count_to_plot=min_column_count_to_plot, min_category_count_to_plot=min_category_count_to_plot,\n",
    "        save_path=save_path, print_save_latex=print_save_latex)\n",
    "\n",
    "\n",
    "def single_ax_bar_chart_from_results(results_by_key, *,\n",
    "    ax=None, figsize=(8, 6), title='', cmap='tab10', \n",
    "    show_legend=True, legend_loc='best', legend_bbox_to_anchor=None, legend_from_color_dict_entries=False,\n",
    "    xlabel='', ylabel='Count',\n",
    "    super_title_fontsize=24, ax_title_fontsize=16, ax_label_fontsize=16, ax_tick_fontsize=12,\n",
    "    inner_key_order=None, outer_key_order=None, inner_keys_to_skip=None, outer_keys_to_skip=None,\n",
    "    normalize_columns=False, vertical_bar_labels=False, \n",
    "    label_join_str=' +\\n', color_dict=None, min_column_count_to_plot=None, min_category_count_to_plot=None,  \n",
    "    save_path=None, print_save_latex=False):\n",
    "\n",
    "    if outer_keys_to_skip is None:\n",
    "        outer_keys_to_skip = []\n",
    "\n",
    "    if inner_keys_to_skip is None:\n",
    "        inner_keys_to_skip = []\n",
    "\n",
    "    if outer_key_order is None:\n",
    "        outer_key_order = sorted(results_by_key.keys())\n",
    "\n",
    "    outer_key_order = [key for key in outer_key_order if key not in outer_keys_to_skip]\n",
    "\n",
    "    if min_category_count_to_plot is not None:\n",
    "        outer_key_sums = [sum(results_by_key[key].values()) for key in outer_key_order]\n",
    "        print({key: sum for key, sum in zip(outer_key_order, outer_key_sums)})\n",
    "        outer_key_order = [key for key, sum in zip(outer_key_order, outer_key_sums) if sum > min_category_count_to_plot]\n",
    "\n",
    "    if inner_key_order is None:\n",
    "        inner_key_order =  sorted(set(\n",
    "            [key for inner_keys in [list(x.keys()) for x in results_by_key.values()] \n",
    "            for key in inner_keys]\n",
    "        ))\n",
    "\n",
    "    inner_key_order = [key for key in inner_key_order if key not in inner_keys_to_skip]\n",
    "\n",
    "    if normalize_columns or min_column_count_to_plot:\n",
    "        inner_key_sums = [sum([results_by_key[outer_key][inner_key] for outer_key in outer_key_order]) \n",
    "            for inner_key in inner_key_order]\n",
    "\n",
    "        if min_column_count_to_plot:\n",
    "            inner_key_order = [inner_key for inner_key, sum in zip(inner_key_order, inner_key_sums) \n",
    "                if sum >= min_column_count_to_plot]\n",
    "            inner_key_sums = [sum for sum in inner_key_sums if sum > min_column_count_to_plot]\n",
    "\n",
    "        if normalize_columns:\n",
    "            if ylabel == 'Count':\n",
    "                ylabel = 'Proportion'\n",
    "\n",
    "            if legend_bbox_to_anchor is None:\n",
    "                legend_bbox_to_anchor = (1.0, 0.5)\n",
    "                legend_loc = 'center left'\n",
    "\n",
    "    if not vertical_bar_labels:\n",
    "        inner_key_names = [key.replace('_', label_join_str) for key in inner_key_order]\n",
    "    else:\n",
    "        inner_key_names = inner_key_order\n",
    "\n",
    "    colormap = plt.cm.get_cmap(cmap)\n",
    "    if color_dict is None:\n",
    "        colors = [colormap(i) for i in range(len(outer_key_order))]\n",
    "    else:\n",
    "        colors = [color_dict[key] for key in outer_key_order]\n",
    "\n",
    "    should_show = False\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = plt.gca()\n",
    "        should_show = True\n",
    "\n",
    "    current_start_values = np.zeros((len(inner_key_order,)))\n",
    "\n",
    "    for index, outer_key in enumerate(outer_key_order):\n",
    "        current_key_values = [results_by_key[outer_key][inner_key] for inner_key in inner_key_order]\n",
    "        if normalize_columns:\n",
    "            current_key_values = [x / y if x != 0 else x for x, y in zip(current_key_values, inner_key_sums)]\n",
    "\n",
    "        # TODO: think about whether or not I want to support non-stacked\n",
    "        ax.bar(inner_key_names, current_key_values, bottom=current_start_values, \n",
    "            label=outer_key, color=colors[index])\n",
    "        current_start_values += np.array(current_key_values)\n",
    "\n",
    "    if show_legend:\n",
    "        if legend_from_color_dict_entries:\n",
    "            legend_handles = [\n",
    "                mpl.patches.Patch(color=color_dict[outer_key], edgecolor=color_dict[outer_key], label=outer_key)\n",
    "                for outer_key in color_dict.keys()\n",
    "            ]\n",
    "            ax.legend(handles=legend_handles, bbox_to_anchor=legend_bbox_to_anchor, loc=legend_loc, prop=dict(size=ax_tick_fontsize))\n",
    "\n",
    "        else:\n",
    "            ax.legend(bbox_to_anchor=legend_bbox_to_anchor, loc=legend_loc, prop=dict(size=ax_tick_fontsize))\n",
    "    ax.set_title(title, fontsize=super_title_fontsize)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=ax_label_fontsize)    \n",
    "    ax.set_ylabel(ylabel, fontsize=ax_label_fontsize)\n",
    "    \n",
    "    bar_label_rotation = vertical_bar_labels\n",
    "    if isinstance(bar_label_rotation, bool):\n",
    "        bar_label_rotation = 90 if bar_label_rotation else 0\n",
    "\n",
    "    # ax.tick_params(axis='x',  labelrotation=bar_label_rotation, )\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), fontsize=ax_tick_fontsize, rotation=bar_label_rotation, ha=\"right\", rotation_mode=\"anchor\") \n",
    "    ax.tick_params(axis='y', labelsize=ax_title_fontsize)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        save_plot(save_path, should_print=print_save_latex)\n",
    "\n",
    "    if should_show:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoocurrenceDefinition:\n",
    "    def __init__(self, outer_key, inner_key, *,\n",
    "        outer_primary_obj_only=True, inner_primary_obj_only=True, \n",
    "        use_categories_outer=False, use_categories_inner=False, name=None):\n",
    "\n",
    "        self.outer_key = outer_key\n",
    "        self.inner_key = inner_key\n",
    "        self.outer_primary_obj_only = outer_primary_obj_only\n",
    "        self.inner_primary_obj_only = inner_primary_obj_only\n",
    "        self.use_categories_outer = use_categories_outer\n",
    "        self.use_categories_inner = use_categories_inner\n",
    "\n",
    "        if name is None:\n",
    "            name_components = [outer_key]\n",
    "            if not outer_primary_obj_only: name_components.append('all')\n",
    "            if use_categories_outer: name_components.append('cat')\n",
    "            name_components.append(inner_key)\n",
    "            if not inner_primary_obj_only: name_components.append('all')\n",
    "            if use_categories_inner: name_components.append('cat')\n",
    "            name = '_'.join(name_components)\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "SplitObjectPredicates = namedtuple(\n",
    "    'SplitObjectPredicates', ('primary_objects', 'secondary_objects', 'predicates')\n",
    ")\n",
    "\n",
    "empty_coocurrence_dict = lambda: defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "def update_coocurrence_dict(cooc_dict, outer_keys, inner_keys, omit_equals=False):\n",
    "    for outer in outer_keys:\n",
    "        for inner in inner_keys:\n",
    "            if omit_equals and outer == inner:\n",
    "                continue\n",
    "\n",
    "            cooc_dict[outer][inner] += 1\n",
    "\n",
    "def sort_by_count_desc(key_to_count):\n",
    "    return [item[0] for item in sorted(key_to_count.items(), key=lambda item: item[1], reverse=True)]\n",
    "\n",
    "\n",
    "def coocurrence_dict_to_matrix(cooc_dict):\n",
    "    outer_key_counts = {key: sum(cooc_dict[key].values()) for key in cooc_dict}\n",
    "    all_inner_keys = set([inner_key for keys in [inner_dict.keys() for inner_dict in cooc_dict.values()] for inner_key in keys])\n",
    "    inner_key_counts = {inner_key: sum([cooc_dict[outer_key][inner_key] for outer_key in cooc_dict]) for inner_key in all_inner_keys}\n",
    "\n",
    "    sorted_outer_keys = sort_by_count_desc(outer_key_counts)\n",
    "    sorted_inner_keys = sort_by_count_desc(inner_key_counts)\n",
    "\n",
    "    cooc_mat = np.zeros((len(sorted_outer_keys), len(sorted_inner_keys)))\n",
    "    for i, outer in enumerate(sorted_outer_keys):\n",
    "        for j, inner in enumerate(sorted_inner_keys):\n",
    "            cooc_mat[i, j] = cooc_dict[outer][inner]\n",
    "\n",
    "    return cooc_mat, sorted_outer_keys, sorted_inner_keys\n",
    "\n",
    "\n",
    "def separate_objects_and_predicates(objects_with_predicates_list):\n",
    "    primary_objects = []\n",
    "    secondary_objects = []\n",
    "    predicates = []\n",
    "\n",
    "    if isinstance(objects_with_predicates_list, list):\n",
    "        for object_with_predicates in objects_with_predicates_list:\n",
    "            primary_objects.append(object_with_predicates['object'])\n",
    "\n",
    "            if 'predicates' in object_with_predicates:\n",
    "                for predicate_desc in object_with_predicates['predicates']:\n",
    "                    if 'object' in predicate_desc:\n",
    "                        secondary_objects.append(predicate_desc['object'])\n",
    "\n",
    "                    if 'predicate' in predicate_desc:\n",
    "                        predicates.append(predicate_desc['predicate'])\n",
    "\n",
    "    return SplitObjectPredicates(primary_objects, secondary_objects, predicates)\n",
    "\n",
    "\n",
    "def extract_all_coocurrences(df, column_prefix, coocurrence_defs, type_to_category_mapping=TYPES_TO_CATEGORIES):\n",
    "    relevant_columns = list(filter(lambda c: c.startswith(f'{column_prefix}_'), df.columns))\n",
    "    obj_with_pred_columns = list(filter(\n",
    "        lambda c: any([isinstance(x, list) and isinstance(x[0], dict) for x in df[c]]), \n",
    "        relevant_columns))\n",
    "    \n",
    "    if any([cooc_def.name is None or cooc_def.inner_key is None or cooc_def.outer_key is None for cooc_def in coocurrence_defs]):\n",
    "        raise ValueError(f'Received at least one cooc def without a name, inner key, or outer key: {coocurrence_defs}')\n",
    "\n",
    "    coocurrence_dicts = {\n",
    "        cooc_def.name: empty_coocurrence_dict()   \n",
    "        for cooc_def in coocurrence_defs\n",
    "    }\n",
    "\n",
    "    for col in obj_with_pred_columns:\n",
    "        coocurrence_dicts[f'{col}_object_predicate'] = empty_coocurrence_dict()\n",
    "        coocurrence_dicts[f'{col}_object_object'] = empty_coocurrence_dict()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        row_values = {col: separate_objects_and_predicates(row[col]) if col in obj_with_pred_columns else row[col] for col in relevant_columns}\n",
    "\n",
    "        # compute predefined coocurrences\n",
    "        for cooc_def in coocurrence_defs:\n",
    "            outer_col = f'{column_prefix}_{cooc_def.outer_key}'\n",
    "            inner_col = f'{column_prefix}_{cooc_def.inner_key}'\n",
    "\n",
    "            outer_values = row_values[outer_col]\n",
    "            inner_values = row_values[inner_col]\n",
    "\n",
    "            if outer_col in obj_with_pred_columns:\n",
    "                if cooc_def.outer_primary_obj_only:\n",
    "                    outer_values = outer_values.primary_objects[:]\n",
    "                else:\n",
    "                    outer_values = outer_values.primary_objects + outer_values.secondary_objects\n",
    "\n",
    "            if cooc_def.use_categories_outer:\n",
    "                outer_values = [type_to_category_mapping[val] for val in outer_values]\n",
    "\n",
    "            if inner_col in obj_with_pred_columns:\n",
    "                if cooc_def.inner_primary_obj_only:\n",
    "                    inner_values = inner_values.primary_objects[:]\n",
    "                else:\n",
    "                    inner_values = inner_values.primary_objects + inner_values.secondary_objects\n",
    "\n",
    "            if cooc_def.use_categories_inner:\n",
    "                inner_values = [type_to_category_mapping[val] for val in inner_values]\n",
    "\n",
    "            update_coocurrence_dict(coocurrence_dicts[cooc_def.name], outer_values, inner_values)\n",
    "\n",
    "        # compute generic object-object and object-predicate coocurrences\n",
    "        for col in obj_with_pred_columns:\n",
    "            if isinstance(row[col], list):\n",
    "                for object_with_predicates in row[col]:\n",
    "                    first_object = object_with_predicates['object']\n",
    "                    if 'predicates' in object_with_predicates:\n",
    "                        for predicate_desc in object_with_predicates['predicates']:\n",
    "                            second_object = None\n",
    "                            if 'object' in predicate_desc:\n",
    "                                second_object = predicate_desc['object']\n",
    "                                coocurrence_dicts[f'{col}_object_object'][first_object][second_object] += 1\n",
    "                                coocurrence_dicts[f'{col}_object_object'][second_object][first_object] += 1\n",
    "\n",
    "                            if 'predicate' in predicate_desc:\n",
    "                                predicate = predicate_desc['predicate']\n",
    "                                \n",
    "                                coocurrence_dicts[f'{col}_object_predicate'][first_object][predicate] += 1\n",
    "                                if second_object:\n",
    "                                    coocurrence_dicts[f'{col}_object_predicate'][second_object][predicate] += 1\n",
    "\n",
    "    # combine the individual object-predicate coocurrences to the combined ones\n",
    "    coocurrence_dicts['all_object_predicate'] = empty_coocurrence_dict()\n",
    "    coocurrence_dicts['all_object_object'] = empty_coocurrence_dict()\n",
    "\n",
    "    for col in obj_with_pred_columns:\n",
    "        for template in '{key}_object_predicate', '{key}_object_object':\n",
    "            overall_cooc_dict = coocurrence_dicts[template.format(key='all')]\n",
    "            current_cooc_dict = coocurrence_dicts[template.format(key=col)]\n",
    "\n",
    "            for outer_key in current_cooc_dict:\n",
    "                for inner_key in current_cooc_dict[outer_key]:\n",
    "                    overall_cooc_dict[outer_key][inner_key] += current_cooc_dict[outer_key][inner_key]\n",
    "\n",
    "    return coocurrence_dicts\n",
    "\n",
    "\n",
    "def plot_coocurrence_data(cooc_dict, title='', xlabel='', ylabel='', figsize=(12, 12),\n",
    "    title_fontsize=24, ax_label_fontsize=20, tick_fontsize=16, cmap='gist_yarg'): \n",
    "    cooc_mat, outer_keys, inner_keys = coocurrence_dict_to_matrix(cooc_dict)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.gca()\n",
    "    plt.imshow(cooc_mat, cmap=cmap)\n",
    "\n",
    "    plt.xticks(np.arange(len(inner_keys)), inner_keys, rotation='vertical', fontsize=tick_fontsize)\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    # ax.xaxis.set_label_position('top')\n",
    "    plt.yticks(np.arange(len(outer_keys)), outer_keys, fontsize=tick_fontsize)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=tick_fontsize)\n",
    "\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=ax_label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=ax_label_fontsize)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potentially relevant plots to the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_colormap = plt.cm.get_cmap('tab20')\n",
    "OBJECT_CATEGORY_TO_COLOR = {obj_category: object_colormap(i) for i, obj_category in enumerate(CATEGORIES_TO_TYPES)}\n",
    "\n",
    "minimal_object_colormap = plt.cm.get_cmap('tab10')\n",
    "MINIMAL_CATEGORIES = (\n",
    "    AGENT, ANY_OBJECT, BALLS, BLOCKS, BUILDING, FURNITURE, \n",
    "    LARGE_OBJECTS, RAMPS, RECEPTACLES, ROOM_FEATURES, SMALL_OBJECTS\n",
    ")\n",
    "MINIMAL_OBJECT_CATEGORY_TO_COLOR = {\n",
    "    obj_category: minimal_object_colormap(i - 1) if i > 0 else (0, 0, 0, 1)\n",
    "    for i, obj_category in enumerate(MINIMAL_CATEGORIES)\n",
    "}\n",
    "\n",
    "single_ax_bar_chart(stats_df, 'game_type', lambda row: row.object_categories_referenced, swap_outer_inner_keys=True,\n",
    "    title='Use of different object categories by game type', xlabel='Game Type', figsize=(12, 6), \n",
    "    color_dict=OBJECT_CATEGORY_TO_COLOR, normalize_columns=True, save_path='object_categories_by_game_type.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the outer keys to be the stacked labels colored differently (in this case, the object categories)\n",
    "# and the inner keys to the things that appear on the x axis (in this case, the predicates)\n",
    "\n",
    "\n",
    "def combine_nested_dict_results(df, nested_dict_field):\n",
    "    combined_results = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for row_results in df[nested_dict_field]:\n",
    "        for outer_key, inner_results in row_results.items():\n",
    "            _add_new_bar_chart_results(combined_results, inner_results, outer_key)\n",
    "\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "category_to_predicate_results_all_games = combine_nested_dict_results(stats_df, 'category_to_pred_counts')\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_all_games, \n",
    "    title='Predicate use by object category', xlabel='Predicate', figsize=(12, 6), legend_loc='upper left',\n",
    "    vertical_bar_labels=True, color_dict=OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=20,\n",
    "    min_category_count_to_plot=30,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_count = defaultdict(int)\n",
    "\n",
    "for category, pred_counts in category_to_predicate_results_all_games.items():\n",
    "    for pred, count in pred_counts.items():\n",
    "        pred_to_count[pred] += count\n",
    "\n",
    "\n",
    "list(sorted(pred_to_count.items(), key=lambda x: x[1], reverse=True))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_by_predicate = defaultdict(int)\n",
    "for cat, pred_counts in category_to_predicate_results_all_games.items():\n",
    "    for pred, count in pred_counts.items():\n",
    "        sum_by_predicate[pred] += count\n",
    "\n",
    "sum_by_predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (left_ax, right_ax) = plt.subplots(1, 2, figsize=(18, 4))\n",
    "fig.subplots_adjust(top=0.775)\n",
    "\n",
    "# throwing_row_selector = stats_df.is_throwing\n",
    "throwing_row_selector = stats_df.game_type_str == 'throwing'\n",
    "\n",
    "category_to_predicate_results_throwing = combine_nested_dict_results(stats_df.loc[throwing_row_selector, :], 'category_to_pred_counts')\n",
    "category_to_predicate_results_non_throwing = combine_nested_dict_results(stats_df.loc[~throwing_row_selector, :], 'category_to_pred_counts')\n",
    "\n",
    "font_inc = -4\n",
    "\n",
    "suptitle_fontsize = 28 + font_inc\n",
    "ax_label_fontsize = 24 + font_inc\n",
    "ax_tick_fontsize = 20 + font_inc\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(\n",
    "    category_to_predicate_results_throwing, title='Exclusively Throwing Games', \n",
    "    xlabel='Predicate', ax=left_ax,\n",
    "    vertical_bar_labels=45, label_join_str='_\\n',\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, \n",
    "    show_legend=False,\n",
    "    min_column_count_to_plot=30, min_category_count_to_plot=30, \n",
    "    ax_label_fontsize=ax_label_fontsize, ax_tick_fontsize=ax_tick_fontsize,\n",
    "    outer_key_order=sorted(MINIMAL_CATEGORIES),\n",
    "    # inner_keys_to_skip=['adjacent_side', 'between'],\n",
    "    # save_path='non_throwing_predicate_use_by_object_category.png'\n",
    ")\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(\n",
    "    category_to_predicate_results_non_throwing, title='Other Games', \n",
    "    xlabel='Predicate', ax=right_ax,\n",
    "    vertical_bar_labels=45, label_join_str='_\\n', \n",
    "    legend_bbox_to_anchor=(1.0, 0.343), legend_loc='center left', legend_from_color_dict_entries=True,\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, \n",
    "    min_column_count_to_plot=10, min_category_count_to_plot=10,\n",
    "    ax_label_fontsize=ax_label_fontsize, ax_tick_fontsize=ax_tick_fontsize,\n",
    "    outer_key_order=sorted(MINIMAL_CATEGORIES),\n",
    "    # inner_keys_to_skip=['adjacent_side', 'between'],\n",
    "    # save_path='throwing_only_predicate_use_by_object_category.png'     \n",
    ")\n",
    "\n",
    "# plt.suptitle('Predicate Use by Object Category', fontsize=suptitle_fontsize)\n",
    "fig.align_labels()\n",
    "# save_plot('side_by_side_predicate_use_by_object_category_vertical_labels_shorter_smaller.pdf')\n",
    "save_plot('game_creation_results_common_sense.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key: category_to_predicate_results_non_throwing[key]['agent'] for key in category_to_predicate_results_non_throwing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_throwing = combine_nested_dict_results(stats_df.loc[stats_df.game_type_str == 'throwing', :], 'category_to_pred_counts')\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_throwing, \n",
    "    title='Predicate use by object category in throwing games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=False, label_join_str='_\\n',\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=20,\n",
    "    min_category_count_to_plot=20,\n",
    "    save_path='throwing_only_predicate_use_by_object_category.png'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_throwing = combine_nested_dict_results(stats_df.loc[stats_df.game_type_str == 'throwing', :], 'category_to_pred_counts')\n",
    "\n",
    "balls_and_blocks_throwing_results = {key: value for key, value in category_to_predicate_results_throwing.items()\n",
    "    if  key in ('balls', 'blocks', 'any_object')}\n",
    "\n",
    "single_ax_bar_chart_from_results(balls_and_blocks_throwing_results, \n",
    "    title='Predicate use by object type in throwing games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=False, label_join_str='_\\n',\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=20,\n",
    "    min_category_count_to_plot=10, ax_tick_fontsize=16, ax_label_fontsize=20,\n",
    "    save_path='throwing_only_predicate_use_by_object_category_balls_and_blocks.png'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "category_to_predicate_results_building = combine_nested_dict_results(stats_df.loc[~stats_df.is_throwing, :], 'category_to_pred_counts')\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_building, \n",
    "    title='Predicate use by object category in non-throwing games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=False, label_join_str='_\\n',\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, \n",
    "    min_column_count_to_plot=10, min_category_count_to_plot=10,\n",
    "    save_path='non_throwing_predicate_use_by_object_category.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_building = combine_nested_dict_results(stats_df.loc[~stats_df.is_throwing, :], 'category_to_pred_counts')\n",
    "\n",
    "balls_and_blocks_non_throwing_results = {key: value for key, value in category_to_predicate_results_building.items()\n",
    "    if  key in ('balls', 'blocks', 'any_object')}\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(balls_and_blocks_non_throwing_results, \n",
    "    title='Predicate use by object type in non-throwing games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=False, label_join_str='_\\n',\n",
    "    color_dict=MINIMAL_OBJECT_CATEGORY_TO_COLOR, ax_tick_fontsize=16, ax_label_fontsize=20,\n",
    "    min_column_count_to_plot=6, min_category_count_to_plot=10,\n",
    "    save_path='non_throwing_predicate_use_by_object_category_balls_blocks.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_building = combine_nested_dict_results(stats_df.loc[stats_df.is_building, :], 'category_to_pred_counts')\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_building, \n",
    "    title='Predicate use by object category in games involving building', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=True, color_dict=OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=10,\n",
    "    save_path='all_building_predicate_use_by_object_category.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_throwing = combine_nested_dict_results(stats_df.loc[stats_df.game_type_str == 'building', :], 'category_to_pred_counts')\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_throwing, \n",
    "    title='Predicate use by object category in building games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=True, color_dict=OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=10,\n",
    "    save_path='building_only_predicate_use_by_object_category.png'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_organizing = combine_nested_dict_results(stats_df.loc[stats_df.is_organizing, :], 'category_to_pred_counts')\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_organizing, \n",
    "    title='Predicate use by object category in games involving organizing', xlabel='Predicate', figsize=(12, 6),  \n",
    "    vertical_bar_labels=True, color_dict=OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=10,\n",
    "    save_path='all_organizing_predicate_use_by_object_category.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_predicate_results_throwing = combine_nested_dict_results(stats_df.loc[stats_df.game_type_str == 'organizing', :], 'category_to_pred_counts')\n",
    "\n",
    "\n",
    "single_ax_bar_chart_from_results(category_to_predicate_results_throwing, \n",
    "    title='Predicate use by object category in organizing games', xlabel='Predicate', figsize=(12, 6), \n",
    "    vertical_bar_labels=True, color_dict=OBJECT_CATEGORY_TO_COLOR, min_column_count_to_plot=10,\n",
    "    save_path='organizing_only_predicate_use_by_object_category.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context sensitivity analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_name_validity_matrix = np.zeros((len(ROOM_NAMES), len(ROOM_NAMES)))\n",
    "for i, room_name in enumerate(ROOM_NAMES):\n",
    "    for j, other_room_name in enumerate(ROOM_NAMES):\n",
    "        room_name_validity_matrix[i, j] = len(stats_df.loc[(stats_df.room_name == room_name) & [other_room_name in rooms for rooms in stats_df.game_valid_rooms]])\n",
    "\n",
    "    room_name_validity_matrix[i, :] /= room_name_validity_matrix[i, i]\n",
    "\n",
    "inner_fontsize = 16\n",
    "outer_fontsize = 20\n",
    "title_fontsize = 24\n",
    "\n",
    "plt.matshow(room_name_validity_matrix, cmap='coolwarm_r')\n",
    "\n",
    "# plt.colorbar()\n",
    "tick_locs = np.arange(len(ROOM_NAMES))\n",
    "# tick_labels = tick_locs + 1\n",
    "tick_labels = ROOM_NAMES\n",
    "plt.xticks(tick_locs, tick_labels, fontsize=inner_fontsize) # , rotation='vertical')\n",
    "plt.yticks(tick_locs, tick_labels, fontsize=inner_fontsize)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='both',length=0)\n",
    "\n",
    "for (i, j), p in np.ndenumerate(room_name_validity_matrix):\n",
    "    ax.text(j, i, '{:0.2f}'.format(p), ha='center', va='center', \n",
    "        size=inner_fontsize)\n",
    "\n",
    "plt.xlabel('Room valid in', fontsize=outer_fontsize)\n",
    "plt.ylabel('Room created in', fontsize=outer_fontsize)\n",
    "plt.title('Context Sensitivity', fontsize=title_fontsize)\n",
    "\n",
    "save_plot('context_sensitivity_validity_matrix.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_repeated_structures = repeated_structures_df.groupby('structure')['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "grouped_repeated_structures.hist(ax=ax, grid=False, bins=32)\n",
    "ax.set_yscale('log')\n",
    "plt.ylabel('log(frequency)', fontsize=16)\n",
    "plt.xlabel('Structure ocurrence count', fontsize=16)\n",
    "plt.title('Abstract Structure Frequency', fontsize=20)\n",
    "# plt.suptitle('Repeated structure count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df.structure_start.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_by_count = grouped_repeated_structures.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "ax = plt.gca()\n",
    "\n",
    "s = repeated_structures_by_count.cumsum() / repeated_structures_by_count.sum()\n",
    "\n",
    "max_pow = int(np.floor(np.log2(len(s))))\n",
    "powers = [2 ** pow - 1 for pow in range(max_pow + 1)]\n",
    "bar_indices = powers + [len(s) - 1]\n",
    "print(bar_indices)\n",
    "\n",
    "s_arr = np.array(s)\n",
    "bar_locs = np.arange(len(bar_indices))\n",
    "plt.bar(bar_locs, s_arr[bar_indices])\n",
    "\n",
    "ax_tick_fontsize = 12\n",
    "ax_label_fontsize = 16\n",
    "title_fontsize = 16\n",
    "\n",
    "\n",
    "plt.ylabel('Proportion', fontsize=ax_label_fontsize)\n",
    "plt.xlabel('N', fontsize=ax_label_fontsize)\n",
    "plt.title('Cumulative proportion of N most common structures', fontsize=title_fontsize)\n",
    "# plt.ylim(0, 1)\n",
    "plt.xticks(bar_locs, [str(pow + 1) for pow in powers] + [f'N={len(s)}'], fontsize=ax_tick_fontsize)\n",
    "plt.yticks(fontsize=ax_tick_fontsize)\n",
    "\n",
    "\n",
    "save_plot('common_structures_shorter.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_by_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = list(repeated_structures_by_count.index)\n",
    "\n",
    "structures = [s for s in repeated_structures_by_count.index if '(not (exists ' in s]\n",
    "for structure in structures:\n",
    "    print(structure, repeated_structures_by_count[structure], index_list.index(structure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PROPORTION = False\n",
    "TOP_VALUES_THRESOLD = 30\n",
    "BOTTOM_VALUES_THRESHOLD = 1\n",
    "cmap = plt.cm.get_cmap('tab10')\n",
    "\n",
    "descending_counts = repeated_structures_by_count.values\n",
    "if PLOT_PROPORTION:\n",
    "    descending_counts = descending_counts / descending_counts.sum()\n",
    "\n",
    "x_values = np.arange(descending_counts.size)\n",
    "\n",
    "top_values_mask = descending_counts >= TOP_VALUES_THRESOLD\n",
    "bottom_values_mask = descending_counts <= BOTTOM_VALUES_THRESHOLD\n",
    "\n",
    "\n",
    "print([x * 255 for x in cmap(0)])\n",
    "print([x * 255 for x in cmap(3)])\n",
    "print([x * 255 for x in cmap(4)])\n",
    "plt.bar(x_values[top_values_mask], descending_counts[top_values_mask], color=cmap(3), label='Top Values')\n",
    "plt.bar(x_values[~top_values_mask & ~bottom_values_mask], descending_counts[~top_values_mask & ~bottom_values_mask], color=cmap(4), label='Middle Values')\n",
    "plt.bar(x_values[bottom_values_mask], descending_counts[bottom_values_mask], color=cmap(0), label='Bottom Values')\n",
    "\n",
    "\n",
    "plt.ylabel(f\"Structure Occurrence {'Proportion' if PLOT_PROPORTION else 'Count'}\", fontsize=ax_label_fontsize)\n",
    "plt.xlabel('Structure Index', fontsize=ax_label_fontsize)\n",
    "# plt.title(f\"{'Proportion' if PLOT_PROPORTION else 'Count'} of N'th most common structure\", fontsize=title_fontsize)\n",
    "\n",
    "plt.xticks(fontsize=ax_tick_fontsize)\n",
    "yticks = plt.yticks()[0]\n",
    "plt.yticks(yticks, fontsize=ax_tick_fontsize)\n",
    "\n",
    "save_plot('game_creation_repeated_structures.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_index = (descending_counts == 1).argmax()\n",
    "descending_counts[5:one_index].sum() / descending_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(descending_counts == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(descending_counts.size)\n",
    "top_values_mask = descending_counts >= TOP_VALUES_THRESOLD\n",
    "bottom_values_mask = descending_counts <= BOTTOM_VALUES_THRESHOLD\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(, descending_counts)\n",
    "\n",
    "\n",
    "plt.ylabel(f\"Structure Occurrence {'Proportion' if PLOT_PROPORTION else 'Count'}\", fontsize=ax_label_fontsize)\n",
    "plt.xlabel('Structure Index', fontsize=ax_label_fontsize)\n",
    "# plt.title(f\"{'Proportion' if PLOT_PROPORTION else 'Count'} of N'th most common structure\", fontsize=title_fontsize)\n",
    "\n",
    "plt.xticks(fontsize=ax_tick_fontsize)\n",
    "yticks = plt.yticks()[0]\n",
    "plt.yticks(yticks, fontsize=ax_tick_fontsize)\n",
    "\n",
    "save_plot('game_creation_repeated_structures.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p in (repeated_structures_by_count / repeated_structures_by_count.sum()).items():\n",
    "    if p > 0.01:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_by_count = repeated_structures_df.sort_values('count')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "s = repeated_structures_by_count['count'].cumsum() / repeated_structures_by_count['count'].sum()\n",
    "\n",
    "# s.plot(kind='bar', ax=ax, grid=False)\n",
    "\n",
    "plt.plot(np.arange(len(s)), s)\n",
    "\n",
    "plt.ylabel('Proportion', fontsize=16)\n",
    "plt.xlabel('Structure index', fontsize=16)\n",
    "plt.title('Cumulative proportion covered by top N structures', fontsize=20)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "ax.get_xaxis().set_ticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.suptitle('Repeated structure count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_by_count = repeated_structures_df.sort_values('count', ascending=False)\n",
    "total = repeated_structures_df['count'].sum()\n",
    "print(total)\n",
    "\n",
    "print(repeated_structures_by_count['count'].head(4).sum() / total)\n",
    "print(repeated_structures_df.loc[repeated_structures_df['count'] <= 1, 'count'].sum() / total)\n",
    "print(repeated_structures_df.loc[repeated_structures_df['count'] <= 1, 'count'].count() / len(repeated_structures_by_count))\n",
    "print(repeated_structures_df.loc[repeated_structures_df['count'] <= 2, 'count'].count() / len(repeated_structures_by_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(repeated_structures_by_count['count'] == 1).sum() / len(repeated_structures_by_count) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between-game-type visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(stats_df, 'game_type', lambda row: row.ast_nodes, \n",
    "    title='Total AST nodes by game type', xlabel='Total AST nodes', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(stats_df, 'game_type', lambda row: row.setup_nodes, \n",
    "    title='Total setup nodes by game type', xlabel='Total setup nodes', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(stats_df, 'game_type', lambda row: row.max_depth, \n",
    "    title='Max depth by game type', xlabel='Max depth', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(stats_df, 'game_type', lambda row: row.num_preferences, \n",
    "    title='Number of preferences by game type', xlabel='# of preferences', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_types_referenced(row):\n",
    "    if isinstance(row.object_types_referenced, dict):\n",
    "        return len(row.object_types_referenced)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "single_ax_histograms(stats_df, 'game_type', extract_num_types_referenced, \n",
    "    title='Total number of types referenced by game type', xlabel='# of types', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_categories_referenced(row):\n",
    "    if isinstance(row.object_categories_referenced, dict):\n",
    "        return len(row.object_categories_referenced)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "single_ax_histograms(stats_df, 'game_type', extract_num_categories_referenced, \n",
    "    title='Total number of object categories referenced by game type', xlabel='# of categories', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predicates_referenced(row):\n",
    "    if isinstance(row.predicates_referenced, dict):\n",
    "        return len(row.predicates_referenced)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "single_ax_histograms(stats_df, 'game_type', extract_predicates_referenced, \n",
    "    title='Total number of predicates referenced by game type', xlabel='# of predicates', \n",
    "    legend_loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two plots, and the two plots that follow, I plot references to types (in the first two) and predicates (in the second two) by game type. The first of each two plots counts individual references to each type (so if a game refers to a type three times, it adds 3), while the second of each two plots counts how many games refer to each type (so hthe same game referring to a type three times will only add 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_bar_chart(stats_df, 'game_type', lambda row: row.object_types_referenced,\n",
    "    title='Total object type references by game type', xlabel='Object type', figsize=(12, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_keys_to_1(row):\n",
    "    if isinstance(row.object_types_referenced, dict):\n",
    "        return {key: 1 for key in row.object_types_referenced}\n",
    "\n",
    "single_ax_bar_chart(stats_df, 'game_type', dict_keys_to_1,\n",
    "    title='Count of games referring to each object type', xlabel='Object type', figsize=(12, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_bar_chart(stats_df, 'game_type', lambda row: row.predicates_referenced,\n",
    "    title='Total predicate references by game type', xlabel='Predicate', figsize=(12, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_keys_to_1(row):\n",
    "    if isinstance(row.predicates_referenced, dict):\n",
    "        return {key: 1 for key in row.predicates_referenced}\n",
    "\n",
    "single_ax_bar_chart(stats_df, 'game_type', dict_keys_to_1,\n",
    "    title='Count of games referring to each predicate', xlabel='Predicate', figsize=(12, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throwing game visualizations\n",
    "\n",
    "* The fiirst set of plots visualize coocurrence matrices between different game elmenets. For example:\n",
    "    * Thrown object <> thrown game goal (to get something in, on, to hit another object, etc.)\n",
    "    * Thrown object <> target object coocurrence\n",
    "    * Coocurrences between various types of objects in the thrown game schema (the object thrown to, the object thrown from, objects and predicates, etc.)\n",
    "* **In all of these, I don't currently control for the fact that same objects appear in more of the rooms -- I could count how many games I have in each room, note which objects appear in each room, and account for that in my analysis, right?**\n",
    "* I can also generate analyses for throwing games like the analyses I generated for all games above. I'll generate a few of those plots, to give some examples, below the cocourrence matrices. Some of the things I could plot include:\n",
    "    * Number of preferences?\n",
    "    * Average length/depth of preferences?\n",
    "    * Max depth?\n",
    "    * Total type references\n",
    "    * Number of types referenced\n",
    "    * **Would complexity of the setup be an interesting thing to quantify?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throwing_df = stats_df[stats_df.is_throwing == 1]\n",
    "\n",
    "throwing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THROWING_COOCURRENCE_DEFINITIONS = (\n",
    "    CoocurrenceDefinition('objects', 'goal'),\n",
    "    CoocurrenceDefinition('objects', 'goal', use_categories_outer=True),\n",
    "    CoocurrenceDefinition('objects', 'to'),\n",
    "    CoocurrenceDefinition('objects', 'to', use_categories_inner=True),\n",
    "    CoocurrenceDefinition('objects', 'on'),\n",
    "    CoocurrenceDefinition('objects', 'on', use_categories_inner=True),\n",
    "    CoocurrenceDefinition('goal', 'to'),\n",
    "    CoocurrenceDefinition('goal', 'to', use_categories_inner=True),\n",
    "    CoocurrenceDefinition('on', 'to'),\n",
    "    CoocurrenceDefinition('from', 'to', outer_primary_obj_only=False, inner_primary_obj_only=False),\n",
    ")\n",
    "\n",
    "throwing_coocurrences = extract_all_coocurrences(throwing_df, 'throwing', THROWING_COOCURRENCE_DEFINITIONS)\n",
    "\n",
    "throwing_coocurrences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['objects_cat_goal'], \n",
    "    'Thrown category <> goal cocurrence', 'Goal', 'Thrown Object Category', (8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['objects_goal'], \n",
    "    'Thrown object <> goal cocurrence', 'Goal', 'Thrown Object', (6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['objects_to'], \n",
    "    'Thrown object <> target object cocurrence', 'Object', 'Thrown Object', (12, 6), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['objects_to_cat'], \n",
    "    'Thrown object <> target object category', 'Object Category', 'Thrown Object', (6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['goal_to'], \n",
    "    'Goal <> target object cocurrence', 'Target Object', 'Goal', (12, 4), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['goal_to_cat'], \n",
    "    'Goal <> target object category', 'Target Object Category', 'Goal', (12, 4), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['on_to'], \n",
    "    'On object <> target object cocurrence', 'Target Object', 'On Object', (12, 4), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['from_to'], \n",
    "    'From object <> target object cocurrence', 'Target Object', 'From Object', (12, 4), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['all_object_predicate'], \n",
    "    'Object <> predicate cocurrence', 'Predicate', 'Object', (12, 8), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurrence_data(throwing_coocurrences['all_object_object'], \n",
    "    'Object <> object cocurrence', 'Object', 'Object', (12, 12), cmap='gist_yarg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throwing game bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_keys_to_1(row):\n",
    "    if isinstance(row.object_types_referenced, dict):\n",
    "        return {key: 1 for key in row.object_types_referenced}\n",
    "\n",
    "single_ax_bar_chart(throwing_df, 'throwing_goal', dict_keys_to_1,\n",
    "    title='Count of throwing games referring to each object type', xlabel='Object type', figsize=(12, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_keys_to_1(row):\n",
    "    if isinstance(row.predicates_referenced, dict):\n",
    "        return {key: 1 for key in row.predicates_referenced}\n",
    "\n",
    "single_ax_bar_chart(throwing_df, 'throwing_goal', dict_keys_to_1,\n",
    "    title='Count of throwing games referring to each predicate', xlabel='Object type', figsize=(12, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(throwing_df, 'throwing_goal', lambda row: row.num_preferences, \n",
    "    title='Total number of preferneces by throwing game type', xlabel='# of preferences', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ax_histograms(throwing_df, 'throwing_goal', lambda row: row.setup_nodes, \n",
    "    title='Total setup nodes by throwing game type', xlabel='Total setup nodes', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df_or_organizing_df = stats_df[np.logical_or(stats_df.is_building == 1, stats_df.is_organizing == 1)]\n",
    "building_df = stats_df[stats_df.is_building == 1]\n",
    "organizing_df = stats_df[stats_df.is_organizing == 1]\n",
    "non_throwing_df = stats_df[stats_df.is_throwing == 0]\n",
    "\n",
    "len(building_df_or_organizing_df), len(building_df), len(organizing_df), len(non_throwing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-throwing game statistics\n",
    "\n",
    "See the above cell -- we have a total of 9 games that don't involve any throwing, or alternatively, a total of 13 games that involve either building or organizing. \n",
    "\n",
    "**Is this enough to separately extract statistics over? Or too little? If yes, anything specific we want to see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.room.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_by_node = stats_df.sort_values('ast_nodes')\n",
    "dup_values = stats_df_by_node.ast_nodes.duplicated(False)\n",
    "\n",
    "stats_df_by_node.loc[dup_values , ['game_name', 'ast_nodes', 'game_type']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = stats_df.sort_values('ast_nodes')\n",
    "sorted_df.loc[(sorted_df.is_throwing == 1) & (sorted_df.setup_nodes > 0), ['game_name', 'ast_nodes', 'game_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = stats_df.sort_values('ast_nodes')\n",
    "sorted_df.loc[sorted_df.is_throwing == 1, ['game_name', 'room_name', 'ast_nodes', 'game_type']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.object_types_referenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def edit_distance_matrix(structure_df):\n",
    "    distances = np.zeros((len(structure_df), len(structure_df)))\n",
    "    for i, structure in enumerate(structure_df.structure):\n",
    "        for j, other_structure in enumerate(structure_df.structure):\n",
    "            distances[i, j] = editdistance.eval(structure, other_structure)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def edit_distance_and_dendrogram(structure_df):\n",
    "    distances = edit_distance_matrix(repeated_structures_df)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(distances, cmap='coolwarm', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    square_distances = squareform(distances)\n",
    "    linkage_matrix = linkage(square_distances, \"single\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    dendrogram(linkage_matrix)\n",
    "    plt.show()\n",
    "\n",
    "edit_distance_and_dendrogram(repeated_structures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df.sort_values('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df[repeated_structures_df.structure_start != 'hold-while' ]['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_structures_df[(repeated_structures_df.structure_start != 'hold-while') & (repeated_structures_df['count'] == 2)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7f8e00f851a7185e5345342178c14041451eaa6562c62790473e641b6de40ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
