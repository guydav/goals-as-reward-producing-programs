{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import difflib\n",
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tatsu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src import fitness_energy_utils as utils\n",
    "from src.fitness_energy_utils import NON_FEATURE_COLUMNS\n",
    "from src.ast_counter_sampler import *\n",
    "from src.ast_utils import cached_load_and_parse_games_from_file, load_games_from_file, _extract_game_id\n",
    "from src import ast_printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = open('../dsl/dsl.ebnf').read()\n",
    "grammar_parser = tatsu.compile(grammar)\n",
    "game_asts = list(cached_load_and_parse_games_from_file('../dsl/interactive-beta.pddl', grammar_parser, False, relative_path='..'))\n",
    "real_game_texts = [ast_printer.ast_to_string(ast, '\\n') for ast in game_asts]\n",
    "regrown_game_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples.pddl'))\n",
    "regrown_game_1024_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples-1024.pddl.gz'))\n",
    "print(len(real_game_texts), len(regrown_game_texts), len(regrown_game_texts) / 98, len(regrown_game_1024_texts), len(regrown_game_1024_texts) / 98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game_index(game_name: str):\n",
    "    first_dash = game_name.find('-')\n",
    "    second_dash = game_name.find('-', first_dash + 1)\n",
    "    index = game_name[first_dash + 1:second_dash] if second_dash != -1 else game_name[first_dash + 1:]\n",
    "    return int(index)\n",
    "\n",
    "\n",
    "def extract_negative_index(game_name: str):\n",
    "    first_dash = game_name.find('-')\n",
    "    second_dash = game_name.find('-', first_dash + 1)\n",
    "    if second_dash == -1:\n",
    "        return -1\n",
    "    \n",
    "    third_dash = game_name.find('-', second_dash + 1)\n",
    "    index = game_name[second_dash + 1:third_dash]\n",
    "    return int(index)\n",
    "\n",
    "\n",
    "fitness_df = utils.load_fitness_data('../data/fitness_features_1024_regrowths.csv.gz')\n",
    "\n",
    "# fitness_df = fitness_df.assign(real=fitness_df.real.astype('int'), game_index=fitness_df.game_name.apply(extract_game_index), \n",
    "#                                negative_index= fitness_df.game_name.apply(extract_negative_index), fake=~fitness_df.real.astype('int'))\n",
    "# fitness_df = fitness_df.sort_values(by=['fake', 'game_index', 'negative_index'], ignore_index=True).reset_index(drop=True)\n",
    "# fitness_df.drop(columns=['Index', 'fake', 'game_index', 'negative_index'], inplace=True)\n",
    "print(fitness_df.src_file.unique())\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_BINARIZED_FEATURES_MODEL = True\n",
    "\n",
    "# if USE_BINARIZED_FEATURES_MODEL:\n",
    "#     model_path = '../models/cv_binarized_model_2023_01_20.pkl.gz'\n",
    "#     data_df = binarized_df\n",
    "# else:\n",
    "#     model_path = '../models/cv_fitness_model_2023_01_20.pkl.gz'\n",
    "#     data_df = filtered_fitness_df\n",
    "from latest_model_paths import LATEST_FITNESS_FUNCTION_DATE_ID, LATEST_SPECIFIC_OBJECTS_FITNESS_FUNCTION_DATE_ID\n",
    "model_date_id = LATEST_FITNESS_FUNCTION_DATE_ID\n",
    "# model_date_id = LATEST_SPECIFIC_OBJECTS_FITNESS_FUNCTION_DATE_ID\n",
    "# model_date_id = 'full_features_no_in_data_all_2023_08_28'\n",
    "data_df = fitness_df\n",
    "cv_energy_model, feature_columns = utils.load_model_and_feature_columns(model_date_id)\n",
    "print(len(feature_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = utils.df_to_tensor(data_df, feature_columns)\n",
    "if 'wrapper' in cv_energy_model.named_steps: cv_energy_model.named_steps['wrapper'].eval()\n",
    "full_tensor_scores = cv_energy_model.transform(full_tensor).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_game_scores = full_tensor_scores[:, 0]\n",
    "\n",
    "print(f'Real game scores: {real_game_scores.mean():.4f} Â± {real_game_scores.std():.4f}, min = {real_game_scores.min():.4f}, max = {real_game_scores.max():.4f}')\n",
    "\n",
    "negatives_scores = full_tensor_scores[:, 1:]\n",
    "torch.quantile(negatives_scores.ravel(), torch.linspace(0, 1, 11))\n",
    "print(f'20th percentile negative energy: {torch.quantile(negatives_scores.ravel(), 0.2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram the weights to get a sense of what we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cv_energy_model.named_steps['fitness'].model.fc1.weight.data.detach().squeeze()  # type: ignore\n",
    "bias = cv_energy_model.named_steps['fitness'].model.fc1.bias.data.detach().squeeze()  # type: ignore\n",
    "print(f'Weights mean: {weights.mean():.4f}, std: {weights.std():.4f}, bias: {bias:.4f}')\n",
    "\n",
    "plt.hist(weights, bins=30)\n",
    "plt.title('Energy model weights')\n",
    "plt.xlabel('Weight magnitude')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "quantile_index = 0\n",
    "\n",
    "abs_weights = weights.abs()\n",
    "\n",
    "for magnitude in torch.linspace(0,abs_weights.max(), 5000):\n",
    "    n = torch.sum(abs_weights < magnitude).item()\n",
    "    if n / len(weights) >= quantiles[quantile_index]:\n",
    "        print(f'Approximately {quantiles[quantile_index] * 100}% ({n}, {n / len(weights) * 100:.2f}%) of the weights have magnitude < {magnitude:.4f}')\n",
    "        quantile_index += 1\n",
    "\n",
    "    if quantile_index >= len(quantiles):\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the top K features most and least predictive of real games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "top_features = torch.topk(weights, K)\n",
    "bottom_features = torch.topk(weights, K, largest=False)\n",
    "\n",
    "lines = []\n",
    "\n",
    "most_predictive_features = []\n",
    "\n",
    "lines.append('### Features with largest negative weights (most predictive of real games):')\n",
    "for i in range(K):\n",
    "    feature_name = feature_columns[bottom_features.indices[i]]\n",
    "    most_predictive_features.append(feature_name.replace('_', '\\\\_'))\n",
    "    lines.append(f'{i+1}. {feature_name} ({bottom_features.values[i]:.4f})')\n",
    "\n",
    "least_predictive_features = []\n",
    "\n",
    "lines.append('### Features with largest positive weights (most predictive of fake games):')\n",
    "for i in range(K):\n",
    "    feature_name = feature_columns[top_features.indices[i]]\n",
    "    least_predictive_features.append(feature_name.replace('_', '\\\\_'))\n",
    "    lines.append((f'{i+1}. {feature_name} ({top_features.values[i]:.4f})'))\n",
    "\n",
    "display(Markdown('\\n'.join(lines)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [r'{\\small', r'\\begin{enumerate}']\n",
    "for name in least_predictive_features:\n",
    "    lines.append(f'\\t\\item \\\\texttt{{{name}}}')\n",
    "\n",
    "lines.append(r'\\end{enumerate}')\n",
    "lines.append(r'}')\n",
    "\n",
    "print('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitness_features_by_category import FEATURE_CATEGORIES\n",
    "\n",
    "abs_weights = weights.abs()\n",
    "sorted_feature_names = [t[1] for t in sorted([(abs_weights[i], feature_columns[i]) for i in range(len(feature_columns))], key=lambda x: x[0], reverse=True)]\n",
    "all_assigned_features = set()\n",
    "\n",
    "for category, features in FEATURE_CATEGORIES.items():\n",
    "    category_feature_list = []\n",
    "    for feature in features:\n",
    "        if isinstance(feature, re.Pattern):\n",
    "            category_feature_list.extend([f for f in feature_columns if feature.match(f)])\n",
    "\n",
    "        else:\n",
    "            category_feature_list.append(feature)\n",
    "\n",
    "    all_assigned_features.update(category_feature_list)\n",
    "    \n",
    "    mean_abs_weight = np.mean([abs_weights[feature_columns.index(feature)] for feature in category_feature_list])\n",
    "    sum_abs_weight = np.sum([abs_weights[feature_columns.index(feature)] for feature in category_feature_list])\n",
    "    mean_sorted_index = np.mean([sorted_feature_names.index(feature) for feature in category_feature_list])\n",
    "    prefix = f'For category {category} with {len(category_feature_list)} features'\n",
    "    print(f'{prefix:54} | mean abs weight is {mean_abs_weight:5.2f} | sum abs weight is {sum_abs_weight:6.2f} | mean sorted index is {mean_sorted_index:6.2f}')\n",
    "\n",
    "\n",
    "unassigned_features = [f for f in feature_columns if f not in all_assigned_features]\n",
    "print(f'Unassigned features: {len(unassigned_features)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[i]) for i, c in enumerate(feature_columns) if c.startswith('max_width_constraints')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[i]) for i, c in enumerate(feature_columns) if 'setup' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.groupby('real').variables_used_incorrect_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[feature_columns.index(c)]) for c in feature_columns if 'once' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[feature_columns.index(c)]) for c in feature_columns if c.startswith('ast_ngram') and c.endswith('score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5.0\n",
    "\n",
    "fs = [c for i, c in enumerate(feature_columns) if \n",
    "      (weights[i].abs() < threshold) and ('arg_types' in c  or c.startswith('compositionality') or c.startswith('predicate_under_'))]\n",
    "\n",
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "s = data_df[data_df.real == 1][fs].mean().sort_values(ascending=False)\n",
    "print(len(s[s > p]))\n",
    "s[s > p].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of the values for each of the and bottom K features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_histograms(df: pd.DataFrame, weights: torch.Tensor, k: int = 10,\n",
    "    largest: bool = True, bins: int = 100, histogram_log_y: bool = True, \n",
    "    histogram_density: bool = True, layout: typing.Optional[typing.Tuple[int, int]] = None,\n",
    "    figsize: typing.Optional[typing.Tuple[float, float]] = None, \n",
    "    panel_width: float = 4, panel_height: float = 4, ylabel_once_per_row: bool = True,\n",
    "    subplots_adjust_params: typing.Optional[typing.Dict[str, float]] = None,\n",
    "    title_fontsize: int = 12, title_split_threshold: int = 25,\n",
    "    cm: plt.get_cmap('tab20') = plt.get_cmap('tab20')):  # type: ignore\n",
    "    \n",
    "    if layout is None:\n",
    "        largest_div = int(np.floor(k ** 0.5))\n",
    "        while k % largest_div != 0:\n",
    "            largest_div -= 1\n",
    "\n",
    "        layout = (largest_div, k // largest_div)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (layout[1] * panel_width, layout[0] * panel_height)\n",
    "\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "\n",
    "    top_k = torch.topk(weights, k, largest=largest)\n",
    "\n",
    "    for i in range(k):\n",
    "        feature_index = top_k.indices[i]\n",
    "        ax = axes[i // layout[1]][i % layout[1]]\n",
    "\n",
    "        real_values = df[df.real == 1][feature_columns[feature_index]].to_numpy()\n",
    "        synthetic_values = df[df.real == 0][feature_columns[feature_index]].to_numpy()\n",
    "\n",
    "        # print(f'Feature = 0 {(real_values == 0).mean() * 100:.2f}% of the time in real games, {(synthetic_values == 0).mean() * 100:.2f}% of the time in synthetic games')\n",
    "\n",
    "        ax.hist([real_values, synthetic_values], label=['Real games', 'Regrown games'], \n",
    "            stacked=False, density=histogram_density, bins=bins, color=[cm.colors[0], cm.colors[2]])  # type: ignore\n",
    "        ax.set_xlabel('Feature value')\n",
    "\n",
    "        if not ylabel_once_per_row or i % layout[1] == 0:\n",
    "            if histogram_density:\n",
    "                if histogram_log_y:\n",
    "                    ax.set_ylabel('log(Density)')\n",
    "                else:\n",
    "                    ax.set_ylabel('Density')\n",
    "            elif histogram_log_y:\n",
    "                ax.set_ylabel('log(Count)')\n",
    "            else:\n",
    "                ax.set_ylabel('Count')\n",
    "\n",
    "        if histogram_log_y:\n",
    "            ax.semilogy()\n",
    "        \n",
    "        title_feature = f'#{i + 1}: {feature_columns[feature_index]}'\n",
    "        title_weight = f'(weight: {top_k.values[i]:.4f})'\n",
    "        if len(title_feature) > title_split_threshold:\n",
    "            title_split_index = title_feature.find('_', title_split_threshold) + 1\n",
    "            if title_split_index == 0:\n",
    "                title_split_index = len(title_feature)\n",
    "            title = f'{title_feature[:title_split_index]}\\n{title_feature[title_split_index:]} {title_weight}'\n",
    "        else:\n",
    "            title = f'{title_feature}\\n{title_weight}'\n",
    "\n",
    "        ax.set_title(title, fontdict=dict(fontsize=title_fontsize))\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "    if subplots_adjust_params is not None:\n",
    "        plt.subplots_adjust(**subplots_adjust_params)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 20 features with the largest negative weights, that is, most predictive of real games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "plot_value_histograms(data_df, weights, k=k, largest=False, bins=20, histogram_log_y=False, histogram_density=True,\n",
    "    subplots_adjust_params=dict(hspace=0.4), title_fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 20 features with largest weights, that is, most predictive of a fake game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_histograms(data_df, weights, k=k, largest=True, bins=20,  histogram_log_y=False, histogram_density=True,\n",
    "    subplots_adjust_params=dict(hspace=0.4), title_fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some top negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = utils.df_to_tensor(data_df, feature_columns)\n",
    "if 'wrapper' in cv_energy_model.named_steps: cv_energy_model.named_steps['wrapper'].eval()\n",
    "full_tensor_scores = cv_energy_model.transform(full_tensor).detach()\n",
    "\n",
    "real_game_scores = full_tensor_scores[:, 0]\n",
    "print(f'Real game scores: {real_game_scores.mean():.4f} Â± {real_game_scores.std():.4f}, min = {real_game_scores.min():.4f}, max = {real_game_scores.max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_energy_histogram(cv_energy_model, full_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cv_sweep_outputs = utils.load_data(model_date_id, 'data/fitness_cv', 'fitness_sweep')\n",
    "print(full_cv_sweep_outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_energy_histogram(\n",
    "    full_cv_sweep_outputs['cv'], \n",
    "    full_cv_sweep_outputs['train_tensor'], \n",
    "    full_cv_sweep_outputs['test_tensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_scores = full_tensor_scores[:, 1:]\n",
    "torch.quantile(negatives_scores.ravel(), torch.linspace(0, 1, 11))\n",
    "torch.quantile(negatives_scores.ravel(), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = full_tensor_scores[:, 0]\n",
    "score_diffs = negatives_scores - positive_scores.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(score_diffs.ravel(), 10, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = (full_tensor[61, 0] - full_tensor[61, 499]).nonzero().squeeze()\n",
    "[feature_columns[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEGATIVES = 20\n",
    "for index in torch.topk(score_diffs.ravel(), N_NEGATIVES, largest=False).indices:\n",
    "    utils.evaluate_energy_contributions(cv_energy_model, full_tensor, index, \n",
    "        feature_columns, full_tensor, real_game_texts, regrown_game_1024_texts, display_features_diff=False, min_display_threshold=0.001)\n",
    "    \n",
    "    display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regrown_game_1024_texts[75 * 1024 + 1012])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we never need to load a featurizer for anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fitness_features import *\n",
    "with gzip.open('../models/fitness_featurizer_2023_03_22.pkl.gz', 'rb') as f:\n",
    "    featurizer = pickle.load(f)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast = grammar_parser.parse(regrown_game_1024_texts[75 * 1024 + 1012])\n",
    "r = featurizer.parse(ast, '', True, False)\n",
    "{k: v for k, v in r.items() if k.startswith('agent_holds') and k.endswith('setup')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = featurizer.parse(ast, '', True, True)\n",
    "{k: v for k, v in r.items() if k.startswith('agent_holds') and k.endswith('setup')}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the role of different variables on the difficulty of the negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_DIFFICULTY_COLUMNS = [\n",
    "    'game_name', 'regrowth_index', \n",
    "    'original_game_name', 'original_game_index', \n",
    "    'node_depth', 'regrowth_depth', \n",
    "    'regrowth_section', 'regrowth_sampler', \n",
    "    'score_diff'\n",
    "]\n",
    "\n",
    "def apply_and_concat(dataframe, field, func, column_names):\n",
    "    return pd.concat((\n",
    "        dataframe,\n",
    "        dataframe[field].apply(\n",
    "            lambda cell: pd.Series(func(cell), index=column_names))), axis=1)\n",
    "\n",
    "\n",
    "game_name_to_index = {game_name: i for i, game_name in enumerate(data_df.loc[data_df.real == 1, 'game_name'])}\n",
    "\n",
    "\n",
    "def extract_info_from_game_name(game_name: str):\n",
    "    i = utils._find_nth(game_name, '-', 2)\n",
    "    original_game_name, regrowth_info = game_name[:i], game_name[i + 1:]\n",
    "    regrowth_index, _, node_depth, _, regrowth_depth, _, regrowth_section, _, regrowth_sampler = regrowth_info.split('-')\n",
    "    regrowth_index = int(regrowth_index)\n",
    "    node_depth = int(node_depth)\n",
    "    regrowth_depth = int(regrowth_depth)\n",
    "    original_game_index = game_name_to_index[original_game_name]\n",
    "    score_diff = score_diffs[original_game_index, regrowth_index].item()\n",
    "    return [regrowth_index, original_game_name, original_game_index, node_depth, regrowth_depth, regrowth_section, regrowth_sampler, score_diff]\n",
    "\n",
    "\n",
    "negative_difficulty_df = data_df.loc[data_df.real == 0, ['game_name']]\n",
    "negative_difficulty_df = apply_and_concat(negative_difficulty_df, 'game_name', extract_info_from_game_name, NEGATIVE_DIFFICULTY_COLUMNS[1:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.groupby('regrowth_sampler').score_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.groupby('regrowth_section').score_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem(x):\n",
    "    return np.std(x) / np.sqrt(len(x))\n",
    "\n",
    "regrowth_depth_impact = negative_difficulty_df.groupby('regrowth_depth').score_diff.agg(['mean', sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(regrowth_depth_impact.index.values, regrowth_depth_impact['mean'].values, 'o', linestyle='-')\n",
    "plt.errorbar(regrowth_depth_impact.index.values, regrowth_depth_impact['mean'].values, regrowth_depth_impact['sem'].values, linestyle='None')\n",
    "plt.xlabel('Regrown tree depth')\n",
    "plt.ylabel('Mean energy difference (lower is harder)')\n",
    "plt.title('Mean energy difference by regrown tree depth')\n",
    "# regrowth_depth_impact['mean']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with knocking out weights below some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = utils.df_to_tensor(data_df, feature_columns)\n",
    "\n",
    "\n",
    "for threshold in (0, 0.1, 0.2, 0.3):\n",
    "    weights = cv_energy_model.named_steps['fitness'].model.fc1.weight.data.detach().squeeze()  # type: ignore\n",
    "    weights[weights.abs() < threshold] = 0\n",
    "    model_copy = copy.deepcopy(cv_energy_model)\n",
    "    model_copy.named_steps['fitness'].model.fc1.weight.data = weights.unsqueeze(0)  # type: ignore\n",
    "\n",
    "    print(f'With threshold = {threshold}:')\n",
    "    print(utils.evaluate_trained_model(model_copy, full_tensor, utils.default_multiple_scoring)) \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b8c8d5c21b7aee7bd0053f69e9c255c013bbea7031fbef7e66d58dd46c0fa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
