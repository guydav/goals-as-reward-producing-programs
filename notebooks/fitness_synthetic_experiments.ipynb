{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import fitness_energy_utils as utils\n",
    "from src.fitness_energy_utils import NON_FEATURE_COLUMNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_df = utils.load_fitness_data()\n",
    "print(fitness_df.columns)\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_syntethic_df(df: pd.DataFrame, \n",
    "    synthetic_data_src_files: typing.Sequence[str] = ('ast-mle-samples.pddl', 'ast-mle-regrowth-samples.pddl')) -> pd.DataFrame:\n",
    "    syntethic_df = fitness_df[fitness_df.src_file.isin(synthetic_data_src_files)].reset_index(drop=True)\n",
    "    if 'ast-mle-samples.pddl' in synthetic_data_src_files:\n",
    "        syntethic_df.loc[syntethic_df.src_file == 'ast-mle-samples.pddl', 'original_game_name'] = syntethic_df.loc[syntethic_df.src_file == 'ast-mle-samples.pddl', 'game_name']\n",
    "\n",
    "    return syntethic_df\n",
    "\n",
    "syntethic_fitness_df = base_syntethic_df(fitness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntethic_fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_games = syntethic_fitness_df[syntethic_fitness_df.src_file == 'ast-mle-regrowth-samples.pddl'].reset_index()\n",
    "broadcasted_original = syntethic_fitness_df.loc[[syntethic_fitness_df.index[(syntethic_fitness_df.game_name == original_name)][0] for original_name in fake_games.original_game_name], :].reset_index()\n",
    "\n",
    "original_regrown_diffs = (broadcasted_original.drop(NON_FEATURE_COLUMNS, axis=1) - fake_games.drop(NON_FEATURE_COLUMNS, axis=1))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "index = 0\n",
    "for column in original_regrown_diffs.columns:\n",
    "    if column in ('index', 'Index', 'real'):\n",
    "        continue\n",
    "\n",
    "    ax = axes[index // 5][index % 5]\n",
    "    ax.hist(original_regrown_diffs[column], bins=20)\n",
    "    ax.set_title(f'{column} diffs')\n",
    "    index += 1\n",
    "\n",
    "plt.show()\n",
    "unchanged_games_prop = (original_regrown_diffs.drop('index', axis=1) == 0).all(axis=1).sum() / len(original_regrown_diffs)\n",
    "print(f'In {unchanged_games_prop * 100:.2f}% of the games, the regrown game was identical to the original game.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a similar process, but taking the max feature value for each original game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "index = 0\n",
    "\n",
    "original_games = syntethic_fitness_df.original_game_name.unique()\n",
    "\n",
    "for column in syntethic_fitness_df.columns:\n",
    "    if column in utils.NON_FEATURE_COLUMNS:\n",
    "        continue\n",
    "\n",
    "    diffs = []\n",
    "    for original_game in original_games:\n",
    "        game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][column]\n",
    "        argmax = game_col.argmax()\n",
    "        diffs.append((game_col - game_col.iloc[argmax])[game_col.index != game_col.index[argmax]].values)\n",
    "        \n",
    "    diffs = np.concatenate(diffs)\n",
    "\n",
    "    ax = axes[index // 5][index % 5]\n",
    "    ax.hist(diffs, bins=20)\n",
    "    ax.set_title(f'{column} diffs')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "index = 0\n",
    "\n",
    "original_games = syntethic_fitness_df.original_game_name.unique()\n",
    "key_column = 'setup_objects_used'\n",
    "\n",
    "game_idxmaxes = syntethic_fitness_df.groupby('original_game_name')[key_column].idxmax()\n",
    "\n",
    "\n",
    "for column in syntethic_fitness_df.columns:\n",
    "    if column in utils.NON_FEATURE_COLUMNS:\n",
    "        continue\n",
    "\n",
    "    diffs = []\n",
    "    for original_game in original_games:\n",
    "        game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][column]\n",
    "        game_idxmax = game_idxmaxes[original_game]\n",
    "        diffs.append((game_col - game_col.loc[game_idxmax])[game_col.index != game_idxmax].values)\n",
    "        \n",
    "    diffs = np.concatenate(diffs)\n",
    "\n",
    "    ax = axes[index // 5][index % 5]\n",
    "    ax.hist(diffs, bins=20)\n",
    "    ax.set_title(f'{column} diffs')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic experiment approach\n",
    "* Pick one feature value that is the 'target' feature for this experiment\n",
    "* For each set of games generated from the same 'source' synthetic game:\n",
    "    * Find the game in that set that has the highest value on that feature\n",
    "    * Define that game to the be positive game for the recovery experiment with this feature; treat the remaining games as the negatives. \n",
    "* At this point, we have a single designated positive game from each set. \n",
    "* Fit the fitness model with these labels.\n",
    "* Check whether or not the highest coefficient belongs to the feature picked initially.\n",
    "* Repeat for other features, and potentially for feature combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(train: pd.DataFrame, feature_columns: typing.List[str], \\\n",
    "    param_grid: typing.Dict[str, typing.Any],\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None, n_folds: int = 5):\n",
    "\n",
    "    train_tensor = utils.df_to_tensor(train, feature_columns)\n",
    "    pipeline = Pipeline(steps=[('scaler', utils.CustomSklearnScaler()), ('fitness', utils.SklearnFitnessWrapper(model_kwargs=model_kwargs, train_kwargs=train_kwargs))])\n",
    "\n",
    "    param_grid['fitness__n_features'] = [len(feature_columns)]\n",
    "    random_seed = train_kwargs['random_seed'] if train_kwargs is not None and 'random_seed' in train_kwargs else None\n",
    "\n",
    "    cv = GridSearchCV(pipeline, param_grid, scoring=scoring_function, cv=KFold(n_folds, shuffle=True, random_state=random_seed), n_jobs=-1, verbose=0)\n",
    "    cv.fit(train_tensor, None)\n",
    "    return cv\n",
    "\n",
    "\n",
    "def single_feature_parameter_recovery_experiment(df: pd.DataFrame, target_feature: str, \n",
    "    param_grid: typing.Dict[str, typing.Any], target_feature_epsilon: float = 0,\n",
    "    feature_columns: typing.Optional[typing.List[str]] = None, \n",
    "    random_seed: int = utils.DEFAULT_RANDOM_SEED,\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    ):\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    if train_kwargs is None:\n",
    "        train_kwargs = {}\n",
    "\n",
    "    syntethic_fitness_df = base_syntethic_df(df)\n",
    "\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "    elif target_feature not in feature_columns:\n",
    "        raise ValueError(f'Target feature {target_feature} not in feature_columns')\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    game_idxmaxes = []\n",
    "    for original_game in syntethic_fitness_df.original_game_name.unique():\n",
    "        game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][target_feature]\n",
    "        idx = rng.choice(np.argwhere(game_col.values == game_col.values.max()).reshape(-1))\n",
    "        game_idxmaxes.append(game_col.index[idx])\n",
    "\n",
    "    syntethic_fitness_df.real = 0\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, 'real'] = 1\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, target_feature] += target_feature_epsilon\n",
    "\n",
    "    feature_group_by = syntethic_fitness_df.groupby('original_game_name')[target_feature].max()\n",
    "\n",
    "    for i, original_game in enumerate(syntethic_fitness_df.original_game_name.unique()):\n",
    "        assert(feature_group_by[original_game] == syntethic_fitness_df.loc[game_idxmaxes[i], target_feature])\n",
    "\n",
    "    train_df, test_df = utils.train_test_split_by_game_name(syntethic_fitness_df, random_seed=random_seed)\n",
    "    cv = cross_validate(train_df, feature_columns, param_grid, scoring_function=scoring_function,\n",
    "        train_kwargs={'random_seed': random_seed, **train_kwargs}, model_kwargs=model_kwargs)\n",
    "    best_model = cv.best_estimator_.named_steps['fitness'].model  # type: ignore\n",
    "    weights = best_model.fc1.weight.detach().numpy().reshape(-1)\n",
    "\n",
    "    target_feature_index = feature_columns.index(target_feature)\n",
    "    target_feature_is_max_weight = weights.argmax() == target_feature_index\n",
    "    target_feature_weight_diff = weights[target_feature_index] - weights[np.arange(len(weights)) != target_feature_index].max()\n",
    "    return {\n",
    "        'target_feature': target_feature,\n",
    "        'random_seed': random_seed,\n",
    "        'is_max_weight': target_feature_is_max_weight,\n",
    "        'weight_diff': target_feature_weight_diff,\n",
    "        'best_params': cv.best_params_,\n",
    "        'best_score': cv.best_score_,\n",
    "        'target_feature_epsilon': target_feature_epsilon,\n",
    "    }\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,]   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "results_by_feature = defaultdict(list)\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "pbar = tqdm.tqdm(total=len(all_feature_columns) * N_SEEDS)\n",
    "\n",
    "for target_feature in all_feature_columns:\n",
    "    pbar.set_description(f'Feature {target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        results_by_feature[target_feature].append(single_feature_parameter_recovery_experiment(syntethic_fitness_df, target_feature, test_param_grid, random_seed=seed))\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "index = 0\n",
    "\n",
    "for target_feature in results_by_feature:\n",
    "    results = results_by_feature[target_feature]\n",
    "    weight_diffs = [r['weight_diff'] for r in results]\n",
    "    ax = axes[index // 5][index % 5]\n",
    "    ax.hist(weight_diffs, bins=5)\n",
    "    ax.set_title(f'{target_feature} weight diffs\\nP(max) = {np.mean([r[\"is_max_weight\"] for r in results]):.2f}')\n",
    "    ax.set_xlabel(f'Weight diff (target - max(others))')\n",
    "    ax.set_ylabel('Count')\n",
    "    index += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_two_feature_parameter_recovery_experiment(df: pd.DataFrame, \n",
    "    positive_target_feature: str, negative_target_feature: str,\n",
    "    param_grid: typing.Dict[str, typing.Any], target_feature_epsilon: float = 0,\n",
    "    feature_columns: typing.Optional[typing.List[str]] = None, \n",
    "    random_seed: int = utils.DEFAULT_RANDOM_SEED,\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,):\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    if train_kwargs is None:\n",
    "        train_kwargs = {}\n",
    "    \n",
    "    syntethic_fitness_df = base_syntethic_df(df)\n",
    "\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "    elif positive_target_feature not in feature_columns:\n",
    "        raise ValueError(f'Positive target feature {positive_target_feature} not in feature_columns')\n",
    "    elif negative_target_feature not in feature_columns:\n",
    "        raise ValueError(f'Negative target feature {negative_target_feature} not in feature_columns')\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    unique_games = list(syntethic_fitness_df.original_game_name.unique())\n",
    "\n",
    "    game_idxmaxes = []\n",
    "    game_values = []\n",
    "    for original_game in unique_games:\n",
    "        pos_game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][positive_target_feature]\n",
    "        neg_game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][negative_target_feature]\n",
    "        diff = pos_game_col - neg_game_col\n",
    "        idx = rng.choice(np.argwhere(diff.values == diff.values.max()).reshape(-1))\n",
    "        game_idxmaxes.append(pos_game_col.index[idx])\n",
    "        game_values.append(diff.values.max())\n",
    "\n",
    "    syntethic_fitness_df.real = 0\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, 'real'] = 1\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, positive_target_feature] += target_feature_epsilon\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, negative_target_feature] -= target_feature_epsilon\n",
    "\n",
    "    feature_combination_group_by = syntethic_fitness_df.groupby('original_game_name').apply(lambda df: df[positive_target_feature] - df[negative_target_feature]).groupby('original_game_name').max()\n",
    "    \n",
    "    for i, original_game in enumerate(unique_games):\n",
    "        assert(feature_combination_group_by[original_game] == (syntethic_fitness_df.loc[game_idxmaxes[i], positive_target_feature] - syntethic_fitness_df.loc[game_idxmaxes[i], negative_target_feature]))  # type: ignore\n",
    "\n",
    "    train_df, test_df = utils.train_test_split_by_game_name(syntethic_fitness_df, random_seed=random_seed)\n",
    "    cv = cross_validate(train_df, feature_columns, param_grid, scoring_function=scoring_function,\n",
    "        train_kwargs={'random_seed': random_seed, **train_kwargs}, model_kwargs=model_kwargs)\n",
    "    best_model = cv.best_estimator_.named_steps['fitness'].model  # type: ignore\n",
    "    weights = best_model.fc1.weight.detach().numpy().reshape(-1)\n",
    "\n",
    "    pos_target_feature_index = feature_columns.index(positive_target_feature)\n",
    "    pos_target_feature_is_max_weight = weights.argmax() == pos_target_feature_index\n",
    "    pos_target_feature_is_min_weight = weights.argmin() == pos_target_feature_index\n",
    "    pos_target_feature_weight_diff = weights[pos_target_feature_index] - weights[np.arange(len(weights)) != pos_target_feature_index].max()\n",
    "\n",
    "    neg_target_feature_index = feature_columns.index(negative_target_feature)\n",
    "    neg_target_feature_is_max_weight = weights.argmax() == neg_target_feature_index\n",
    "    neg_target_feature_is_min_weight = weights.argmin() == neg_target_feature_index\n",
    "    neg_target_feature_weight_diff = weights[neg_target_feature_index] - weights[np.arange(len(weights)) != neg_target_feature_index].min()\n",
    "\n",
    "    return {\n",
    "        'pos_target_feature': positive_target_feature,\n",
    "        'neg_target_feature': negative_target_feature,\n",
    "        'random_seed': random_seed,\n",
    "        'pos_is_max_weight': pos_target_feature_is_max_weight,\n",
    "        'pos_is_min_weight': pos_target_feature_is_min_weight,\n",
    "        'pos_weight_diff': pos_target_feature_weight_diff,\n",
    "        'neg_is_max_weight': neg_target_feature_is_max_weight,\n",
    "        'neg_is_min_weight': neg_target_feature_is_min_weight,\n",
    "        'neg_weight_diff': neg_target_feature_weight_diff,\n",
    "        'best_params': cv.best_params_,\n",
    "        'best_score': cv.best_score_,\n",
    "        'target_feature_epsilon': target_feature_epsilon,\n",
    "    }\n",
    "    \n",
    "\n",
    "DEFAULT_LEGEND_KWARGS = dict(loc='upper left', bbox_to_anchor=(1.05, 1.425))\n",
    "DEFAULT_SUBPLOT_ADJUST_PARAMS = dict(hspace=0.35, wspace=0.3)\n",
    "    \n",
    "def plot_two_feature_parameter_recovery_experiment_results(\n",
    "    results_by_feature: typing.Dict[typing.Tuple[str, str], typing.List[typing.Dict[str, typing.Any]]], \n",
    "    feature_columns: typing.List[str], flip_features: bool = False,\n",
    "    layout: typing.Tuple[int, int] = (2, 5), figsize: typing.Tuple[int, int] = (20, 10),\n",
    "    title: typing.Optional[str] = None, colormap: str = 'tab10',\n",
    "    legend_kwargs: typing.Dict[str, typing.Any] = DEFAULT_LEGEND_KWARGS,\n",
    "    subplot_adjust_params: typing.Dict[str, typing.Any] = DEFAULT_SUBPLOT_ADJUST_PARAMS,\n",
    "    ):\n",
    "\n",
    "    cmap = plt.get_cmap(colormap)  # type: ignore\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "    index = 0\n",
    "\n",
    "    for target_feature in feature_columns:\n",
    "        positive_keys = [k for k in results_by_feature.keys() if k[0] == target_feature]\n",
    "        negative_keys = [k for k in results_by_feature.keys() if k[1] == target_feature]\n",
    "\n",
    "        positive_results = [results_by_feature[k] for k in positive_keys]\n",
    "        negative_results = [results_by_feature[k] for k in negative_keys]\n",
    "\n",
    "        positive_weight_diffs = [r['pos_weight_diff'] for r in itertools.chain(*positive_results)]\n",
    "        negative_weight_diffs = [r['neg_weight_diff'] for r in itertools.chain(*negative_results)]\n",
    "\n",
    "        if flip_features:\n",
    "            max_key = 'neg_is_max_weight'\n",
    "            min_key = 'pos_is_min_weight'\n",
    "        else:\n",
    "            max_key = 'pos_is_max_weight'\n",
    "            min_key = 'neg_is_min_weight'\n",
    "\n",
    "        feature_is_max_weight = [r[max_key] for r in itertools.chain(*positive_results)]\n",
    "        feature_is_min_weight = [r[min_key] for r in itertools.chain(*negative_results)]\n",
    "\n",
    "        ax = axes[index // 5][index % 5]\n",
    "        positive_color, negative_color = cmap(0), cmap(1)\n",
    "        if flip_features:\n",
    "            positive_color, negative_color = negative_color, positive_color\n",
    "\n",
    "        ax.hist(positive_weight_diffs, color=positive_color, label='Positive feature\\nregression weight')\n",
    "        ax.hist(negative_weight_diffs, color=negative_color, label='Negative feature\\nregression weight')\n",
    "\n",
    "        max_mean, min_mean = np.mean(feature_is_max_weight), np.mean(feature_is_min_weight)\n",
    "        ax.set_title(f'{target_feature} weight diffs\\nP(min) = {min_mean:.2f} | P(max) = {max_mean:.2f}')\n",
    "        ax.set_xlabel(f'Weight diff (target - max/min(others))')\n",
    "        ax.set_ylabel('Count')\n",
    "        index += 1\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    plt.legend(**legend_kwargs)\n",
    "    plt.subplots_adjust(**subplot_adjust_params)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,]   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "\n",
    "two_feature_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(two_feature_results_by_feature, all_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,],\n",
    "    'fitness__margin': [1, 2, 4],   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_hinge_loss}\n",
    "\n",
    "two_feature_hinge_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_hinge_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_hinge_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,]   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_log_loss}\n",
    "\n",
    "two_feature_log_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_log_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_log_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,],\n",
    "    'fitness__margin': [1, 2, 4],   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_square_square_loss}\n",
    "\n",
    "two_feature_square_square_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_square_square_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_square_square_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging thoughts about these new losses\n",
    "* Plot my loss implementations to make sure they behave as expected\n",
    "* Verify my scoring function works and the model returned is actually the best one\n",
    "* Try the square-square loss as well\n",
    "* Cross validate over other margins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7f8e00f851a7185e5345342178c14041451eaa6562c62790473e641b6de40ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
