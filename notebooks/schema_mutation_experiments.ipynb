{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "from collections import defaultdict, Counter, namedtuple\n",
    "from itertools import combinations\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import json\n",
    "import python_jsonschema_objects as pjs\n",
    "PROJECT_PATH = '/Users/guydavidson/projects/game-generation-modeling'\n",
    "sys.path.append(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "from schema.validate_schema import load_and_validate_game_schema\n",
    "SCHEMA_FILE = '../schema/game_schema_with_refs.json'\n",
    "GAME_SCHEMAS_FILE = '../schema/interactive_beta.json'\n",
    "with open(SCHEMA_FILE, 'r') as schema_file:\n",
    "    schema = json.load(schema_file)\n",
    "game_schemas = load_and_validate_game_schema(GAME_SCHEMAS_FILE, SCHEMA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_RANDOM_SEED = 33\n",
    "\n",
    "\n",
    "class PriorBase:\n",
    "    def __init__(self, key, seed=DEFAULT_RANDOM_SEED):\n",
    "        self.key = key\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.is_fit = False\n",
    "        self.samples = []\n",
    "\n",
    "    def add_observation(self, observation):\n",
    "        self._add_observation(observation)\n",
    "        self.is_fit = False\n",
    "        \n",
    "    def _add_observation(self, observation):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def fit(self):\n",
    "        self._fit()\n",
    "        self.is_fit = True\n",
    "\n",
    "    def _fit(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def sample(self, sample_params=None):\n",
    "        if sample_params is None:\n",
    "            sample_params = dict()\n",
    "        \n",
    "        if self.is_fit:\n",
    "            sample = self._sample(sample_params)\n",
    "            self.samples.append(sample)\n",
    "            return sample\n",
    "        else:\n",
    "            print('Call fit() before attempting to sample')\n",
    "    \n",
    "    def _sample(self, sample_params=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class ArrayPrior(PriorBase):\n",
    "    def __init__(self, key, item_prior, seed=DEFAULT_RANDOM_SEED):\n",
    "        super().__init__(key, seed)\n",
    "        self.item_prior = item_prior\n",
    "        self.lengths = []\n",
    "\n",
    "        self.duplicates_observed = False\n",
    "        self.lambda_mle = None\n",
    "\n",
    "    def _add_observation(self, observation):\n",
    "        if observation is None or not observation:\n",
    "            self.lengths.append(0)\n",
    "\n",
    "        elif isinstance(observation, list):\n",
    "            self.lengths.append(len(observation))\n",
    "        \n",
    "            if hasattr(observation[0], '__hash__') and observation.__hash__ is not None and len(set(observation)) < len(observation):\n",
    "                self.duplicates_observed = True\n",
    "\n",
    "            for item in observation:\n",
    "                self.item_prior.add_observation(item)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'ArrayPrior expected to receive a list obervation, instead received a {type(observation)}: {observation}')\n",
    "\n",
    "    def _fit(self):\n",
    "        self.lambda_mle = np.mean(self.lengths)\n",
    "        self.observed_lambda_mle = np.mean([l for l in self.lengths if l > 0])\n",
    "        self.item_prior.fit()\n",
    "\n",
    "    def _sample(self, sample_params=None):\n",
    "        if 'required' in sample_params and sample_params['required']:\n",
    "            sample_length = 0 \n",
    "            while sample_length == 0:\n",
    "                sample_length = self.rng.poisson(self.observed_lambda_mle)\n",
    "\n",
    "        else:    \n",
    "            sample_length = self.rng.poisson(self.lambda_mle)\n",
    "            if sample_length == 0:\n",
    "                return None\n",
    "\n",
    "        array_prefix = f'[]{KEY_DELIMITER}'\n",
    "        child_params = {key.replace(array_prefix, ''): value for key, value in sample_params.items() if key.startswith(array_prefix)}\n",
    "\n",
    "        if self.duplicates_observed:\n",
    "            return [self.item_prior.sample(child_params) for _ in range(sample_length)]\n",
    "\n",
    "        sample = []\n",
    "        while len(sample) < sample_length:\n",
    "            candidate = self.item_prior.sample(child_params)\n",
    "            if candidate not in sample:\n",
    "                sample.append(candidate)\n",
    "\n",
    "        return sample\n",
    "\n",
    "DEFAULT_EPSILON = 0.05\n",
    "\n",
    "\n",
    "class EnumPrior(PriorBase):\n",
    "    def __init__(self, key, options, epsilon=DEFAULT_EPSILON, seed=DEFAULT_RANDOM_SEED):\n",
    "        super().__init__(key, seed)\n",
    "        self.epsilon = epsilon\n",
    "        self.options = list(options)\n",
    "        self.counts = {option: 0 for option in options}\n",
    "        self.counts[None] = 0\n",
    "\n",
    "        self.observed_options = []\n",
    "        self.probabilities = None\n",
    "\n",
    "    def _add_observation(self, observation):\n",
    "        if observation is None:\n",
    "            self.counts[None] += 1\n",
    "\n",
    "        elif observation not in self.counts:\n",
    "            raise ValueError(f'EnumItemPrior received an observation {observation} that was not in the initialized counts: {self.counts}')\n",
    "        \n",
    "        self.counts[observation] += 1\n",
    "\n",
    "    def _fit(self):\n",
    "        self.observed_options = [opt for opt in self.options if self.counts[opt] > 0]\n",
    "        self.probabilities = np.array([self.counts[opt] for opt in self.observed_options])\n",
    "        self.probabilities = self.probabilities / self.probabilities.sum()\n",
    "\n",
    "    def _sample(self, sample_params=None):\n",
    "        if self.rng.uniform() < self.epsilon:\n",
    "            return self.rng.choice(self.options)\n",
    "        \n",
    "        return self.rng.choice(self.observed_options, p=self.probabilities)\n",
    "\n",
    "\n",
    "REQUIRED = 'required'\n",
    "OMIT = 'omit'\n",
    "\n",
    "\n",
    "class ObjectItemPrior(PriorBase):\n",
    "    def __init__(self, key, properties_to_priors, required_properties, keys_to_skip=None, seed=DEFAULT_RANDOM_SEED):\n",
    "        super().__init__(key, seed)\n",
    "        self.properties_to_priors = properties_to_priors\n",
    "        self.required_properties = required_properties\n",
    "        if keys_to_skip is None:\n",
    "            keys_to_skip = []\n",
    "        self.keys_to_skip = keys_to_skip\n",
    "        \n",
    "        self.observed_count = 0\n",
    "        self.unobserved_count = 0\n",
    "\n",
    "    def _add_observation(self, observation):\n",
    "        if observation is None:\n",
    "            self.unobserved_count += 1\n",
    "            return\n",
    "        \n",
    "        for property in observation:\n",
    "            if property not in self.properties_to_priors and property not in self.keys_to_skip:\n",
    "                raise ValueError(f'ObjectItemPrior received unexpected property \"{property}\", expected only the following: {list(self.properties_to_priors.keys())}')\n",
    "\n",
    "        for property in self.properties_to_priors:\n",
    "            if property not in observation and property in self.required_properties:\n",
    "                raise ValueError(f'ObjectItemPrior expected to receive required property \"{property}\", expecting the following: {list(self.properties_to_priors.keys())}')\n",
    "\n",
    "            if property in observation:\n",
    "                self.properties_to_priors[property].add_observation(observation[property])\n",
    "\n",
    "            else:\n",
    "                self.properties_to_priors[property].add_observation(None)\n",
    "        \n",
    "        self.observed_count += 1\n",
    "\n",
    "    def _fit(self):\n",
    "        total_count = self.observed_count + self.unobserved_count\n",
    "        if total_count == 0:\n",
    "            self.observe_p = 0\n",
    "\n",
    "        else:\n",
    "            self.observe_p = self.observed_count / total_count\n",
    "        \n",
    "        for prior in self.properties_to_priors.values():\n",
    "            prior.fit()\n",
    "\n",
    "    def _sample(self, sample_params=None):\n",
    "        required = ('required' in sample_params and sample_params['required'])\n",
    "        if required and self.observe_p == 0:\n",
    "            raise ValueError(f'Cannot require to sample ObjectItemPrior {self.key} which has never been observed')\n",
    "\n",
    "        if required or self.rng.uniform() < self.observe_p:\n",
    "            sample = {}\n",
    "            for property, prior in self.properties_to_priors.items():\n",
    "                property_params = {}\n",
    "                if property in sample_params:\n",
    "                    if sample_params[property] == REQUIRED or property in self.required_properties:\n",
    "                        property_params[REQUIRED] = True\n",
    "                    elif sample_params[property] == OMIT:\n",
    "                        continue\n",
    "                    \n",
    "                property_prefix = f'{property}{KEY_DELIMITER}'\n",
    "                child_params = {key.replace(property_prefix, ''): value for key, value in sample_params.items() if key.startswith(property_prefix)}\n",
    "                property_params.update(child_params)\n",
    "                sample_value = prior.sample(property_params)\n",
    "                if sample_value is not None:\n",
    "                    sample[property] = sample_value\n",
    "\n",
    "            return sample\n",
    "\n",
    "\n",
    "class BooleanPrior(PriorBase):\n",
    "    def __init__(self, key, default_value=None, epsilon=DEFAULT_EPSILON, seed=DEFAULT_RANDOM_SEED):\n",
    "        super().__init__(key, seed)\n",
    "        self.default_value = default_value\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = {False: 0, True: 0}\n",
    "        if self.default_value is None:\n",
    "            self.counts[None] = 0\n",
    "\n",
    "        self.observed_options = []\n",
    "        self.probabilities = None\n",
    "\n",
    "    def _add_observation(self, observation):\n",
    "        if observation is None:\n",
    "            if self.default_value is None:\n",
    "                self.counts[None] += 1\n",
    "\n",
    "            else:\n",
    "                self.counts[self.default_value] += 1\n",
    "\n",
    "        elif isinstance(observation, bool):\n",
    "            self.counts[observation] += 1\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'BooleanPrior expected a boolean observation, received {observation}')\n",
    "\n",
    "    def _fit(self):\n",
    "        self.observed_options = [opt for opt in self.counts if self.counts[opt] > 0]\n",
    "        self.probabilities = np.array([self.counts[opt] for opt in self.observed_options])\n",
    "        self.probabilities = self.probabilities / self.probabilities.sum()\n",
    "\n",
    "    def _sample(self, sample_params=None):\n",
    "        if self.rng.uniform() < self.epsilon:\n",
    "            sample = self.rng.choice(list(self.counts.keys()))\n",
    "        else:\n",
    "            sample = self.rng.choice(self.observed_options, p=self.probabilities)\n",
    "\n",
    "        if self.default_value is not None and sample == self.default_value:\n",
    "            return None\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "DEFS_KEY = '$defs'\n",
    "REF_KEY = '$ref'\n",
    "KEY_DELIMITER = '/'\n",
    "DEFAULT_KEYS_TO_SKIP = ('metadata',)\n",
    "\n",
    "\n",
    "class SchemaPriorParser:\n",
    "    def __init__(self, schema, keys_to_skip=DEFAULT_KEYS_TO_SKIP, kwargs_by_prior_class=None):\n",
    "        self.schema_dict = {}\n",
    "        self.schema = schema\n",
    "        self.keys_to_skip = keys_to_skip\n",
    "\n",
    "        self.kwargs_by_prior_class = defaultdict(dict)\n",
    "        if kwargs_by_prior_class is not None:\n",
    "            self.kwargs_by_prior_class.update(kwargs_by_prior_class)\n",
    "\n",
    "        self.ref_prior_generators = {}\n",
    "        self.ref_options = defaultdict(set)\n",
    "        \n",
    "        self._parse_defs()\n",
    "        self.schema_prior = self._parse()\n",
    "\n",
    "    def _ref_key(self, key):\n",
    "        return f'#/{DEFS_KEY}/{key}'\n",
    "\n",
    "    def _parse_defs(self):\n",
    "        defs_section = self.schema[DEFS_KEY]\n",
    "\n",
    "        key_to_ref_dependencies = {key: self._recursive_find_refs(defs_section[key]) for key in defs_section}\n",
    "        \n",
    "        while key_to_ref_dependencies:\n",
    "            keys_with_no_unresolved_dependencies = [key for key, deps in key_to_ref_dependencies.items() if len(deps) == 0]\n",
    "\n",
    "            for key in keys_with_no_unresolved_dependencies:\n",
    "                self._resolve_refs(key, defs_section[key])\n",
    "                del key_to_ref_dependencies[key]\n",
    "                for deps in key_to_ref_dependencies.values():\n",
    "                    ref_key = self._ref_key(key)\n",
    "                    if ref_key in deps:\n",
    "                        deps.remove(ref_key)\n",
    "\n",
    "    def _recursive_find_refs(self, start_dict):\n",
    "        frontier = [start_dict]\n",
    "        refs = set()\n",
    "        while frontier:\n",
    "            current = frontier.pop()\n",
    "            new_values = None\n",
    "\n",
    "            if isinstance(current, dict):\n",
    "                if REF_KEY in current:\n",
    "                    refs.add(current[REF_KEY])\n",
    "\n",
    "                new_values = current.values()\n",
    "\n",
    "            elif isinstance(current, (list, tuple)):\n",
    "                new_values = current\n",
    "\n",
    "            frontier.extend([value for value in new_values if isinstance(value, (list, dict, tuple))])\n",
    "\n",
    "        return refs\n",
    "\n",
    "    def _resolve_refs(self, key, ref_def):\n",
    "        ref_key = self._ref_key(key)\n",
    "\n",
    "        if 'enum' in ref_def:\n",
    "            self.ref_options[ref_key].update(ref_def['enum'])\n",
    "            \n",
    "            def gen(path_key):\n",
    "                return EnumPrior(f'{path_key}{KEY_DELIMITER}{key}', self.ref_options[ref_key], **self.kwargs_by_prior_class[EnumPrior])\n",
    "\n",
    "            self.ref_prior_generators[ref_key] = gen\n",
    "\n",
    "        elif 'anyOf' in ref_def:\n",
    "            for any_ref_def in ref_def['anyOf']:\n",
    "                for any_key, any_value in any_ref_def.items():\n",
    "                    if any_key == REF_KEY:\n",
    "                        self.ref_options[ref_key].update(self.ref_options[any_value])\n",
    "                    elif any_key == 'const':\n",
    "                        self.ref_options[ref_key].add(any_value)\n",
    "                    else:\n",
    "                        raise ValueError(f'Encountered unexpected key/value pairing in anyOf: {any_key}: {any_value}')\n",
    "\n",
    "            def gen(path_key):\n",
    "                return EnumPrior(f'{path_key}{KEY_DELIMITER}{key}', self.ref_options[ref_key], **self.kwargs_by_prior_class[EnumPrior])\n",
    "\n",
    "            self.ref_prior_generators[ref_key] = gen\n",
    "\n",
    "        elif 'type' in ref_def:\n",
    "            def gen(path_key):\n",
    "                return self._parse(ref_def, f'{path_key}{KEY_DELIMITER}{key}')\n",
    "\n",
    "            self.ref_prior_generators[ref_key] = gen\n",
    "\n",
    "    def _parse_enum(self, schema_obj, key):\n",
    "        if 'enum' not in schema_obj:\n",
    "            raise ValueError('_parse_enum was called without an enum key in the object: {schema_obj}')\n",
    "\n",
    "        options = schema_obj['enum']\n",
    "        return EnumPrior(key, options, **self.kwargs_by_prior_class[EnumPrior])\n",
    "\n",
    "    def _parse_array(self, schema_obj, key):\n",
    "        if 'items' not in schema_obj:\n",
    "            raise ValueError(f'_parse_array received array without items key, currently unsupported: {schema_obj}')\n",
    "\n",
    "        sub_key = f'{key}{KEY_DELIMITER}[]'\n",
    "        item_prior = self._parse(schema_obj['items'], sub_key)\n",
    "        return ArrayPrior(sub_key, item_prior, **self.kwargs_by_prior_class[ArrayPrior])\n",
    "\n",
    "    def _parse_object(self, schema_obj, key):\n",
    "        if 'properties' not in schema_obj:\n",
    "            raise ValueError(f'_parse_object was called without properties key, currently unsupported: {schema_obj}')\n",
    "\n",
    "        properties_to_priors = {prop_key: self._parse(prop_value, f'{key}{KEY_DELIMITER}{prop_key}') \n",
    "            for prop_key, prop_value \n",
    "            in schema_obj['properties'].items()\n",
    "            if prop_key not in self.keys_to_skip}\n",
    "        reqiured_properties = schema_obj['required_properties'] if 'required_properties' in schema_obj else []\n",
    "        return ObjectItemPrior(key, properties_to_priors, reqiured_properties, keys_to_skip=self.keys_to_skip, **self.kwargs_by_prior_class[ObjectItemPrior])\n",
    "\n",
    "    def _parse_boolean(self, schema_obj, key):\n",
    "        default_value = schema_obj['default'] if 'default' in schema_obj else None\n",
    "        return BooleanPrior(key, default_value, **self.kwargs_by_prior_class[BooleanPrior])\n",
    "\n",
    "    def _parse(self, schema_obj=None, key=None):\n",
    "        if schema_obj is None:\n",
    "            schema_obj = self.schema\n",
    "\n",
    "        if key is None:\n",
    "            key = ''\n",
    "\n",
    "        if '$ref' in schema_obj:\n",
    "            return self.ref_prior_generators[schema_obj['$ref']](key)\n",
    "\n",
    "        if 'enum' in schema_obj:\n",
    "            return self._parse_enum(schema_obj, key)\n",
    "\n",
    "        if 'type' in schema_obj:\n",
    "            schema_type = schema_obj['type']\n",
    "\n",
    "            if schema_type == 'array':\n",
    "                return self._parse_array(schema_obj, key)\n",
    "\n",
    "            elif schema_type == 'object':\n",
    "                return self._parse_object(schema_obj, key)\n",
    "\n",
    "            elif schema_type == 'boolean':\n",
    "                return self._parse_boolean(schema_obj, key)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Encountered schema which did not match any rule: {schema_obj}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "prior = SchemaPriorParser(schema).schema_prior\n",
    "for game in game_schemas:\n",
    "    prior.add_observation(game)\n",
    "prior.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next stages\n",
    "* Prior-sampling:\n",
    "    * Controllable sampling -- be able to sample a game with specific fields (at least the top-level ones)\n",
    "    * Related: understand why I'm currently getting games with fields missing -- could it be that the sampling result is an empty dict, etc.? How can it happen with mandatory fields? \n",
    "    * Curate some games\n",
    "* **Tree-based mutation:**\n",
    "    * Keep a mapping of full path to value\n",
    "    * Assuming I'll start by mutating same path => same path, rather than same type => same type\n",
    "    * Implement replacements, additions (in arrays), and deletions (ditto)\n",
    "    * Note I can also add a field that doesn't exist (e.g. from, on) or delete a non-required field entirely\n",
    "    * Curate some games\n",
    "* **Share samples of original games and both mutated types with Todd and Brenden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_p = prior.properties_to_priors['organizing']\n",
    "b_p = prior.properties_to_priors['building']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'throwing': {'what': ['golfball'],\n",
       "  'from': [{'object': 'rug',\n",
       "    'predicates': [{'object': 'desk', 'predicate': 'adjacent'}]}],\n",
       "  'on': [{'object': 'curved_wooden_ramp',\n",
       "    'predicates': [{'object': 'hexagonal_bin', 'predicate': 'touch'}]}],\n",
       "  'goal': ['in'],\n",
       "  'to': [{'object': 'hexagonal_bin',\n",
       "    'predicates': [{'object': 'room_center', 'predicate': 'on'}]}]},\n",
       " 'organizing': [{'what': ['desktop', 'alarm_clock', 'cellphone'],\n",
       "   'to': [{'object': 'laptop'}]}]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior.sample({'throwing': 'required', 'building': 'omit', 'throwing/from': 'required'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organizing': [{'what': ['laptop', 'book'], 'from': {'object': 'room_side'}}]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior.sample({'throwing': 'omit', 'building': 'omit', 'organizing': 'required'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record full paths for mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_game_by_keys(mapping, schema_obj, key=None, keys_to_skip=DEFAULT_KEYS_TO_SKIP):\n",
    "    if key is None:\n",
    "        key = ''\n",
    "\n",
    "    if isinstance(schema_obj, dict):\n",
    "        if key:\n",
    "            mapping[key].append(schema_obj)\n",
    "        for inner_key, inner_value in schema_obj.items():\n",
    "            if inner_key in keys_to_skip: \n",
    "                continue\n",
    "\n",
    "            new_key = f'{key}{KEY_DELIMITER}{inner_key}' if key else inner_key\n",
    "            parse_game_by_keys(mapping, inner_value, new_key, keys_to_skip)\n",
    "\n",
    "    elif isinstance(schema_obj, (list, tuple)):\n",
    "        new_key = f'{key}{KEY_DELIMITER}[]'\n",
    "        for inner_value in schema_obj:\n",
    "            parse_game_by_keys(mapping, inner_value, new_key, keys_to_skip)\n",
    "\n",
    "    else:\n",
    "        mapping[key].append(schema_obj)\n",
    "\n",
    "\n",
    "mapping = defaultdict(list)\n",
    "for game in game_schemas:\n",
    "    parse_game_by_keys(mapping, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['throwing', 'throwing/what/[]', 'throwing/on/[]', 'throwing/on/[]/object', 'throwing/on/[]/predicates/[]', 'throwing/on/[]/predicates/[]/object', 'throwing/on/[]/predicates/[]/predicate', 'throwing/goal/[]', 'throwing/to/[]', 'throwing/to/[]/object', 'throwing/from/[]', 'throwing/from/[]/object', 'throwing/from/[]/predicates/[]', 'throwing/from/[]/predicates/[]/predicate', 'throwing/to/[]/predicates/[]', 'throwing/to/[]/predicates/[]/predicate', 'building', 'building/objects/[]', 'building/structure', 'building/goal', 'throwing/to/[]/predicates/[]/object', 'building/order/[]', 'building/on', 'building/on/object', 'building/on/predicates/[]', 'building/on/predicates/[]/object', 'building/on/predicates/[]/predicate', 'organizing/[]', 'organizing/[]/what/[]', 'organizing/[]/to/[]', 'organizing/[]/to/[]/object', 'organizing/[]/to/[]/predicates/[]', 'organizing/[]/to/[]/predicates/[]/object', 'organizing/[]/to/[]/predicates/[]/predicate', 'organizing/[]/to/[]/predicates/[]/negate', 'throwing/on/[]/predicates/[]/negate', 'throwing/from/[]/predicates/[]/object', 'organizing/[]/from', 'organizing/[]/from/object', 'throwing/from/[]/predicates/[]/negate'])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7f8e00f851a7185e5345342178c14041451eaa6562c62790473e641b6de40ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
